{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMYMJnQLrHlOfdBRfd6wSLn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NkosinathiNtuli-Signalcompvision/Pytorch-computer-/blob/main/Intro_To_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cliO_V3W0wfx",
        "outputId": "69b49f1b-c302-4071-9857-47a5f2a268c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open mydata.zip, mydata.zip.zip or mydata.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!unzip -q mydata.zip -d mydata\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DataLoad:\n",
        "    def __init__(self, datapath=None, outdir=None, classes=None, target_size=(224, 224)):\n",
        "        self.datapath = datapath\n",
        "        self.outdir = outdir\n",
        "        self.CLASSES = classes\n",
        "        self.target_size = target_size\n",
        "        logging.info(f'DataLoad instantiated with datapath={self.datapath}, outdir={self.outdir}, target_size={self.target_size}')\n",
        "\n",
        "    def build(self):\n",
        "        X, y = [], []\n",
        "        class_names = sorted(os.listdir(self.datapath)) if self.CLASSES is None else self.CLASSES\n",
        "\n",
        "        for idx, cls in enumerate(class_names):\n",
        "            cls_path = Path(self.datapath, cls)\n",
        "            if not cls_path.is_dir():\n",
        "                continue\n",
        "            for file in cls_path.glob(\"**/*.png\"):\n",
        "                img = plt.imread(file)\n",
        "                if len(img.shape) == 2:  # grayscale\n",
        "                    img = np.expand_dims(img, axis=-1)\n",
        "                img_resized = tf.image.resize(img, self.target_size).numpy()\n",
        "                X.append(img_resized)\n",
        "                y.append(idx)\n",
        "\n",
        "        np.savez(self.outdir, X=np.array(X), y=np.array(y), C=class_names)\n",
        "        logging.info(f\"Processed {len(X)} images into {self.outdir}\")\n",
        "\n",
        "    def load(self):\n",
        "        if not Path(self.outdir).is_file():\n",
        "            logging.warning(f\"{self.outdir} not found. Building dataset.\")\n",
        "            self.build()\n",
        "        with np.load(self.outdir, allow_pickle=True) as data:\n",
        "            self.X = data['X']\n",
        "            self.y = data['y']\n",
        "            self.CLASSES = list(data['C'])\n",
        "        self.X_ = self.standardize()\n",
        "        logging.info(f\"Loaded {self.X.shape[0]} samples from {self.outdir}\")\n",
        "\n",
        "    def standardize(self):\n",
        "        return np.divide((self.X - self.X.mean(axis=0)), self.X.std(axis=0),\n",
        "                         out=np.zeros_like((self.X - self.X.mean(axis=0))),\n",
        "                         where=self.X.std(axis=0)!=0)\n",
        "\n",
        "\n",
        "class SaliencyHandler:\n",
        "    \"\"\" Handles loading models and computing saliency maps with proper input size. \"\"\"\n",
        "    def __init__(self, models_folder, data_folder):\n",
        "        self.models_folder = models_folder\n",
        "        self.data_folder = data_folder\n",
        "        self.MODELS = [DenseNet121, EfficientNetV2S, InceptionV3, InceptionResNetV2, Xception,\n",
        "                       ResNet50, ResNet50V2, VGG16, VGG19]\n",
        "\n",
        "    def get_input_shape(self, model_class):\n",
        "        if model_class in [EfficientNetV2S, DenseNet121, ResNet50, ResNet50V2, VGG16, VGG19]:\n",
        "            return (224, 224, 3)\n",
        "        elif model_class in [InceptionV3, InceptionResNetV2, Xception]:\n",
        "            return (299, 299, 3)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown model class: {model_class}\")\n",
        "\n",
        "    def load_data_for_model(self, model_class):\n",
        "        input_shape = self.get_input_shape(model_class)\n",
        "        dataset_file = Path(self.data_folder, f\"data_{input_shape[0]}x{input_shape[1]}.npz\")\n",
        "        data_loader = DataLoad(datapath=self.data_folder, outdir=dataset_file, target_size=input_shape[:2])\n",
        "        data_loader.load()\n",
        "        return data_loader\n",
        "\n",
        "    def run_saliency_loop(self):\n",
        "        for model_class in self.MODELS:\n",
        "            logging.info(f\"Processing saliency for {model_class.__name__}\")\n",
        "\n",
        "            # Load dataset adapted for this model\n",
        "            data_loader = self.load_data_for_model(model_class)\n",
        "\n",
        "            # Load model from saved folder\n",
        "            model_path = Path(self.models_folder, f\"{model_class.__name__}.keras\")\n",
        "            model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "            # Here you would call your saliency function using model and data_loader.X_\n",
        "            # For example: compute_saliency(model, data_loader.X_, data_loader.y)\n",
        "\n"
      ],
      "metadata": {
        "id": "eXylNstr1WCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lDCzpoNVZr-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "y63flbv1Zs8M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start here\n"
      ],
      "metadata": {
        "id": "lQnebplIZuJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIoNZWrEaOD0",
        "outputId": "3caeb339-cf2b-4dc2-86ee-298d7f0009a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import logging\n",
        "import time\n",
        "from pathlib import Path\n",
        "from typing import Callable, Sequence, Optional\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.applications import (\n",
        "    VGG16, VGG19, ResNet50, Xception, ResNet50V2,\n",
        "    InceptionV3, DenseNet121, EfficientNetV2S, InceptionResNetV2\n",
        ")\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import interpolate, stats\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# ----------------------------\n",
        "# Logging setup\n",
        "# ----------------------------\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# PIC Metric & Image Utils\n",
        "# ----------------------------\n",
        "def estimate_image_entropy(im_orig: np.ndarray) -> float:\n",
        "    p = np.histogram(im_orig, bins=256, range=(im_orig.min(), im_orig.max()), density=True)[0]\n",
        "    return stats.entropy(p, base=2)\n",
        "\n",
        "def estimate_entropy(image: np.ndarray) -> float:\n",
        "    if image.dtype in [np.float32, np.float64]:\n",
        "        image = (image - np.min(image)) / (np.max(image) - np.min(image)) * 255\n",
        "        image = image.astype(np.uint8)\n",
        "    if len(image.shape) == 2:\n",
        "        pil_image = Image.fromarray(image)\n",
        "    elif len(image.shape) == 3 and image.shape[2] == 1:\n",
        "        pil_image = Image.fromarray(image[:, :, 0])\n",
        "    else:\n",
        "        pil_image = Image.fromarray(image)\n",
        "    buffer = io.BytesIO()\n",
        "    pil_image.save(buffer, format='webp', lossless=True, quality=100)\n",
        "    length = buffer.tell()\n",
        "    buffer.close()\n",
        "    return length\n",
        "\n",
        "def create_blurred_image(full_img: np.ndarray, pixel_mask: np.ndarray, method: str = 'linear') -> np.ndarray:\n",
        "    img_type = full_img.dtype\n",
        "    if full_img.ndim == 2:\n",
        "        full_img = np.expand_dims(full_img, axis=2)\n",
        "    channels = full_img.shape[2]\n",
        "\n",
        "    # always include corners\n",
        "    pixel_mask = pixel_mask.copy()\n",
        "    h, w = pixel_mask.shape\n",
        "    pixel_mask[[0, 0, h-1, h-1], [0, w-1, 0, w-1]] = True\n",
        "\n",
        "    mean_color = np.mean(full_img, axis=(0,1))\n",
        "    if np.all(pixel_mask):\n",
        "        return full_img\n",
        "\n",
        "    blurred_img = full_img * np.expand_dims(pixel_mask, axis=2).astype(np.float32)\n",
        "\n",
        "    for c in range(channels):\n",
        "        points = np.argwhere(pixel_mask)\n",
        "        values = full_img[:, :, c][tuple(points.T)]\n",
        "        unknown_points = np.argwhere(~pixel_mask)\n",
        "        interpolated = interpolate.griddata(points, values, unknown_points, method=method, fill_value=mean_color[c])\n",
        "        blurred_img[:, :, c][tuple(unknown_points.T)] = interpolated\n",
        "\n",
        "    if full_img.shape[2] == 1:\n",
        "        blurred_img = blurred_img[:, :, 0]\n",
        "    if np.issubdtype(img_type, np.integer):\n",
        "        blurred_img = np.round(blurred_img)\n",
        "    return blurred_img.astype(img_type)\n",
        "\n",
        "\n",
        "from collections import namedtuple\n",
        "PicMetricResult = namedtuple(\"PicMetricResult\", [\"curve_x\", \"curve_y\", \"blurred_images\", \"predictions\", \"thresholds\", \"auc\"])\n",
        "\n",
        "def compute_pic_metric(\n",
        "    img: np.ndarray,\n",
        "    saliency_map: np.ndarray,\n",
        "    random_mask: np.ndarray,\n",
        "    pred_func: Callable[[np.ndarray], Sequence[float]],\n",
        "    saliency_thresholds: Sequence[float],\n",
        "    keep_monotonous: bool = True,\n",
        "    num_data_points: int = 1000,\n",
        "    experiment: Optional[str] = \"base\",\n",
        "):\n",
        "    blurred_images = []\n",
        "    predictions = []\n",
        "    entropy_pred_tuples = []\n",
        "\n",
        "    fully_blurred_img = create_blurred_image(img, random_mask)\n",
        "    if experiment == \"base\":\n",
        "        orig_entropy = estimate_image_entropy(img)\n",
        "        fully_blurred_entropy = estimate_image_entropy(fully_blurred_img)\n",
        "    elif experiment == \"kapis\":\n",
        "        orig_entropy = estimate_entropy(img)\n",
        "        fully_blurred_entropy = estimate_entropy(fully_blurred_img)\n",
        "    else:\n",
        "        orig_entropy = (estimate_entropy(img) + estimate_image_entropy(img))/2\n",
        "        fully_blurred_entropy = (estimate_entropy(fully_blurred_img) + estimate_image_entropy(fully_blurred_img))/2\n",
        "\n",
        "    orig_pred = pred_func(img[np.newaxis, ...])[0]\n",
        "    fully_blurred_pred = pred_func(fully_blurred_img[np.newaxis, ...])[0]\n",
        "\n",
        "    blurred_images.append(fully_blurred_img)\n",
        "    predictions.append(fully_blurred_pred)\n",
        "\n",
        "    max_pred = 0.0\n",
        "    for threshold in saliency_thresholds:\n",
        "        quant = np.quantile(saliency_map, 1 - threshold)\n",
        "        mask = np.logical_or(saliency_map >= quant, random_mask)\n",
        "        b_img = create_blurred_image(img, mask)\n",
        "        if experiment == \"base\":\n",
        "            entropy = estimate_image_entropy(b_img)\n",
        "        elif experiment == \"kapis\":\n",
        "            entropy = estimate_entropy(b_img)\n",
        "        else:\n",
        "            entropy = (estimate_entropy(b_img) + estimate_image_entropy(b_img))/2\n",
        "        pred = pred_func(b_img[np.newaxis, ...])[0]\n",
        "\n",
        "        normalized_entropy = np.clip((entropy - fully_blurred_entropy)/(orig_entropy - fully_blurred_entropy), 0.0, 1.0)\n",
        "        normalized_pred = np.clip((pred - fully_blurred_pred)/(orig_pred - fully_blurred_pred), 0.0, 1.0)\n",
        "        max_pred = max(max_pred, normalized_pred)\n",
        "        if keep_monotonous:\n",
        "            entropy_pred_tuples.append((normalized_entropy, max_pred))\n",
        "        else:\n",
        "            entropy_pred_tuples.append((normalized_entropy, normalized_pred))\n",
        "\n",
        "        blurred_images.append(b_img)\n",
        "        predictions.append(pred)\n",
        "\n",
        "    # interpolate PIC curve\n",
        "    entropy_pred_tuples.append((0.0, 0.0))\n",
        "    entropy_pred_tuples.append((1.0, 1.0))\n",
        "    x_data, y_data = zip(*entropy_pred_tuples)\n",
        "    interp = interpolate.interp1d(x_data, y_data)\n",
        "    curve_x = np.linspace(0.0, 1.0, num_data_points, endpoint=False)\n",
        "    curve_y = np.array([interp(x) for x in curve_x])\n",
        "    curve_x = np.append(curve_x, 1.0)\n",
        "    curve_y = np.append(curve_y, 1.0)\n",
        "    auc = np.trapz(curve_y, curve_x)\n",
        "    thresholds = [0.0] + list(saliency_thresholds) + [1.0]\n",
        "\n",
        "    blurred_images.append(img)\n",
        "    predictions.append(orig_pred)\n",
        "\n",
        "    return PicMetricResult(curve_x, curve_y, blurred_images, predictions, thresholds, auc)\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Data Loader\n",
        "# ----------------------------\n",
        "class DataLoad:\n",
        "    def __init__(self, datapath=None, outdir=None, classes=None, target_size=(224, 224)):\n",
        "        self.datapath = datapath\n",
        "        self.outdir = outdir\n",
        "        self.CLASSES = classes\n",
        "        self.target_size = target_size\n",
        "        logging.info(f'DataLoad instantiated with datapath={datapath}, outdir={outdir}, target_size={target_size}')\n",
        "\n",
        "    def build(self):\n",
        "        X, y = [], []\n",
        "        class_names = sorted(os.listdir(self.datapath)) if self.CLASSES is None else self.CLASSES\n",
        "        for idx, cls in enumerate(class_names):\n",
        "            cls_path = Path(self.datapath, cls)\n",
        "            if not cls_path.is_dir():\n",
        "                continue\n",
        "            for file in cls_path.glob(\"**/*.png\"):\n",
        "                img = plt.imread(file)\n",
        "                if len(img.shape) == 2:\n",
        "                    img = np.expand_dims(img, axis=-1)\n",
        "                img_resized = tf.image.resize(img, self.target_size).numpy()\n",
        "                X.append(img_resized)\n",
        "                y.append(idx)\n",
        "        np.savez(self.outdir, X=np.array(X), y=np.array(y), C=class_names)\n",
        "        logging.info(f\"Processed {len(X)} images into {self.outdir}\")\n",
        "\n",
        "    def load(self):\n",
        "        if not Path(self.outdir).is_file():\n",
        "            logging.warning(f\"{self.outdir} not found. Building dataset.\")\n",
        "            self.build()\n",
        "        with np.load(self.outdir, allow_pickle=True) as data:\n",
        "            self.X = data['X']\n",
        "            self.y = data['y']\n",
        "            self.CLASSES = list(data['C'])\n",
        "        self.X_ = self.standardize()\n",
        "        logging.info(f\"Loaded {self.X.shape[0]} samples from {self.outdir}\")\n",
        "\n",
        "    def standardize(self):\n",
        "        return np.divide((self.X - self.X.mean(axis=0)), self.X.std(axis=0),\n",
        "                         out=np.zeros_like((self.X - self.X.mean(axis=0))),\n",
        "                         where=self.X.std(axis=0)!=0)\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Saliency Handler\n",
        "# ----------------------------\n",
        "class SaliencyHandler:\n",
        "    def __init__(self, models_folder, data_folder):\n",
        "        self.models_folder = models_folder\n",
        "        self.data_folder = data_folder\n",
        "        self.MODELS = [DenseNet121, EfficientNetV2S, InceptionV3, InceptionResNetV2, Xception,\n",
        "                       ResNet50, ResNet50V2, VGG16, VGG19]\n",
        "\n",
        "    def get_input_shape(self, model_class):\n",
        "        if model_class in [EfficientNetV2S, DenseNet121, ResNet50, ResNet50V2, VGG16, VGG19]:\n",
        "            return (224, 224, 3)\n",
        "        elif model_class in [InceptionV3, InceptionResNetV2, Xception]:\n",
        "            return (299, 299, 3)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown model class: {model_class}\")\n",
        "\n",
        "    def load_data_for_model(self, model_class):\n",
        "        input_shape = self.get_input_shape(model_class)\n",
        "        dataset_file = Path(self.data_folder, f\"data_{input_shape[0]}x{input_shape[1]}.npz\")\n",
        "        data_loader = DataLoad(datapath=self.data_folder, outdir=dataset_file, target_size=input_shape[:2])\n",
        "        data_loader.load()\n",
        "        return data_loader\n",
        "\n",
        "    def run_saliency_loop(self, saliency_func: Callable):\n",
        "        for model_class in self.MODELS:\n",
        "            logging.info(f\"Processing saliency for {model_class.__name__}\")\n",
        "\n",
        "            data_loader = self.load_data_for_model(model_class)\n",
        "            model_path = Path(self.models_folder, f\"{model_class.__name__}.keras\")\n",
        "            model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "            # Compute saliency maps for all images\n",
        "            saliency_maps = [saliency_func(model, img) for img in data_loader.X_]\n",
        "\n",
        "            # Compute PIC metrics\n",
        "            results = []\n",
        "            for img, sal_map, label in zip(data_loader.X_, saliency_maps, data_loader.y):\n",
        "                random_mask = np.zeros_like(sal_map, dtype=bool)\n",
        "                pic_result = compute_pic_metric(\n",
        "                    img=img,\n",
        "                    saliency_map=sal_map,\n",
        "                    random_mask=random_mask,\n",
        "                    pred_func=lambda x: model(x, training=False).numpy()[0],\n",
        "                    saliency_thresholds=np.linspace(0.1, 0.9, 9)\n",
        "                )\n",
        "                results.append(pic_result)\n",
        "\n",
        "            logging.info(f\"Finished saliency and PIC computation for {model_class.__name__}\")\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Example Usage\n",
        "# ----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    models_folder = '/content/drive/MyDrive/Signal Processing ML/Audio Mel-spectrogram/Study sites/Port of St Francies/Models_LR1_0.001_Reg_0.01/'\n",
        "    data_folder = '/content/drive/MyDrive/Signal Processing ML/Audio Mel-spectrogram/Study sites/Port of St Francies/Test/'\n",
        "\n",
        "    handler = SaliencyHandler(models_folder=models_folder, data_folder=data_folder)\n",
        "\n",
        "    # Define a dummy saliency function (replace with your actual implementation)\n",
        "    def dummy_saliency_func(model, img):\n",
        "        # just return a random map with same shape as image\n",
        "        return np.random.rand(*img.shape[:2])\n",
        "\n",
        "    handler.run_saliency_loop(dummy_saliency_func)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "7fLrpyMrGCoG",
        "outputId": "811d7863-0ec1-4d27-b33e-21d2655fb6d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:/content/drive/MyDrive/Signal Processing ML/Audio Mel-spectrogram/Study sites/Port of St Francies/Test/data_224x224.npz not found. Building dataset.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "File not found: filepath=/content/drive/MyDrive/Signal Processing ML/Audio Mel-spectrogram/Study sites/Port of St Francies/Models_LR1_0.001_Reg_0.01/DenseNet121.keras. Please ensure the file is an accessible `.keras` zip file.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3254960296.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     \u001b[0mhandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_saliency_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_saliency_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3254960296.py\u001b[0m in \u001b[0;36mrun_saliency_loop\u001b[0;34m(self, saliency_func)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data_for_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{model_class.__name__}.keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;31m# Compute saliency maps for all images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[1;32m    198\u001b[0m         )\n\u001b[1;32m    199\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    201\u001b[0m             \u001b[0;34mf\"File not found: filepath={filepath}. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;34m\"Please ensure the file is an accessible `.keras` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: File not found: filepath=/content/drive/MyDrive/Signal Processing ML/Audio Mel-spectrogram/Study sites/Port of St Francies/Models_LR1_0.001_Reg_0.01/DenseNet121.keras. Please ensure the file is an accessible `.keras` zip file."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gkyrV3PNb5aL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The previous code is data loader and pIC matric"
      ],
      "metadata": {
        "id": "wrOByZyPb7Pk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import click\n",
        "import logging\n",
        "import os\n",
        "from pathlib import Path\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "\n",
        "from data import DataLoad\n",
        "from utils import Utils\n",
        "from model import Models\n",
        "from Download import downloader\n",
        "from saliencyAnalysis import Saliency, Main\n",
        "import saliency.core as saliency\n",
        "from saliency.metrics import pic\n",
        "from pic import (\n",
        "    compute_pic_metric, estimate_image_entropy, create_blurred_image,\n",
        "    estimate_entropy, estimate_image_avg_entropy, compute_pic_metric_flag\n",
        ")\n",
        "from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n",
        "from tf_keras_vis.utils.scores import CategoricalScore\n",
        "from tf_keras_vis.utils import normalize\n",
        "from tf_keras_vis.gradcam import Gradcam\n",
        "from tf_keras_vis.gradcam_plus_plus import GradcamPlusPlus\n",
        "from tf_keras_vis.scorecam import Scorecam\n",
        "\n",
        "# Ignore numpy warnings\n",
        "np.seterr(divide='ignore', invalid='ignore')\n",
        "\n",
        "CUSTOM_DATASETS = [\"./Data/brainTumorDataPublic\", \"./Data/COVID-19_Radiography_Dataset\"]\n",
        "FONT_SIZE = 14\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Utility functions for plotting\n",
        "# ------------------------------\n",
        "def show_image(im, title='', ax=None):\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    ax.axis('off')\n",
        "    ax.imshow(im, cmap='gray')\n",
        "    ax.set_title(title, fontsize=FONT_SIZE)\n",
        "\n",
        "\n",
        "def show_grayscale_image(im, title='', ax=None):\n",
        "    if ax is None:\n",
        "        plt.figure()\n",
        "    plt.axis('off')\n",
        "    plt.imshow(im, cmap=plt.cm.gray, vmin=0, vmax=1)\n",
        "    plt.title(title, fontsize=FONT_SIZE)\n",
        "\n",
        "\n",
        "def show_curve_xy(x, y, title='PIC', label=None, color='blue', ax=None):\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    auc = np.trapz(y) / y.size\n",
        "    label = f'{label}, AUC={auc:.3f}'\n",
        "    ax.plot(x, y, label=label, color=color)\n",
        "    ax.set_title(title, fontsize=FONT_SIZE)\n",
        "    ax.set_xlim([0.0, 1.1])\n",
        "    ax.set_ylim([-0.1, 1.1])\n",
        "    ax.set_xlabel('Normalized estimation of entropy', fontsize=FONT_SIZE)\n",
        "    ax.set_ylabel('Predicted score', fontsize=FONT_SIZE)\n",
        "    ax.legend(fontsize=FONT_SIZE)\n",
        "    ax.grid(True)\n",
        "\n",
        "\n",
        "def show_curve(compute_pic_metric_result, title='PIC', label=None, color='blue', ax=None):\n",
        "    show_curve_xy(compute_pic_metric_result.curve_x,\n",
        "                  compute_pic_metric_result.curve_y,\n",
        "                  title=title, label=label, color=color, ax=ax)\n",
        "\n",
        "\n",
        "def show_blurred_images_with_scores(compute_pic_metric_result):\n",
        "    images_to_display = compute_pic_metric_result.blurred_images\n",
        "    scores = compute_pic_metric_result.predictions\n",
        "    thresholds = compute_pic_metric_result.thresholds\n",
        "\n",
        "    nrows = (len(images_to_display) - 1) // 5 + 1\n",
        "    fig, ax = plt.subplots(nrows=nrows, ncols=5, figsize=(20, 20 / 5 * nrows))\n",
        "    for i, im in enumerate(images_to_display):\n",
        "        row = i // 5\n",
        "        col = i % 5\n",
        "        title = f'Score: {scores[i]:.3f}\\nThreshold: {thresholds[i]:.3f}'\n",
        "        show_image(im, title=title, ax=ax[row, col])\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Prediction functions\n",
        "# ------------------------------\n",
        "def create_predict_function_softmax(class_idx, model):\n",
        "    def predict(image_batch):\n",
        "        score = model(image_batch)[:, class_idx]\n",
        "        return score.numpy()\n",
        "    return predict\n",
        "\n",
        "\n",
        "def create_predict_function_accuracy(class_idx, model):\n",
        "    def predict(image_batch):\n",
        "        scores = model(image_batch)\n",
        "        arg_max = np.argmax(scores, axis=1)\n",
        "        accuracy = arg_max == class_idx\n",
        "        return np.ones_like(arg_max) * accuracy\n",
        "    return predict\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# Main PIC computation function\n",
        "# ------------------------------\n",
        "def compute_pic_score(dl, model_indx, masked=True, ds=\"BrainTumor\", experiments=\"base\", n_samples=1000):\n",
        "    models = Main.load_models(n=3, file_path=f\"./Data/{ds}_Evaluation_Results.csv\")\n",
        "    model = tf.keras.models.load_model(f\"./Models/{ds}_{models[model_indx]}.keras\")\n",
        "    logging.info(\"Computing saliency masks...\")\n",
        "\n",
        "    idxs = Saliency.pick_indices(dl, n=3)\n",
        "    sa = Saliency(model, dl, idxs, masked=masked, dataset=ds)\n",
        "\n",
        "    guided_ig = saliency.GuidedIG()\n",
        "    gradient_saliency = saliency.GradientSaliency()\n",
        "    saliency_thresholds = [0.005, 0.01, 0.02, 0.03, 0.04, 0.05, 0.07, 0.10, 0.13, 0.21, 0.34, 0.5, 0.75]\n",
        "\n",
        "    # Initialize result lists\n",
        "    gig_aic, rnd_aic, gig_sic, rnd_sic = [], [], [], []\n",
        "    vanilla_aic, smoothgrad_aic, vanilla_sic, smoothgrad_sic = [], [], [], []\n",
        "    xrai_aic, xrai_sic, gradcam_aic, gradcam_sic = [], [], [], []\n",
        "    gradcamplusplus_aic, gradcamplusplus_sic, scorecam_aic, scorecam_sic = [], [], [], []\n",
        "\n",
        "    for idx, im_orig in enumerate(dl.X_):\n",
        "        replace2linear = ReplaceToLinear()\n",
        "        score = CategoricalScore([dl.y[idx]])\n",
        "        predictions, prediction_class, call_model_args, pred_prob = sa.predict(im_orig)\n",
        "\n",
        "        # Create a random mask for PIC calculation\n",
        "        random_mask = pic.generate_random_mask(im_orig.shape[0], im_orig.shape[1], fraction=0.01)\n",
        "        fully_blurred_img = create_blurred_image(full_img=im_orig, pixel_mask=random_mask)\n",
        "\n",
        "        if experiments == \"base\":\n",
        "            original_img_entropy = estimate_image_entropy(im_orig)\n",
        "            fully_blurred_img_entropy = estimate_image_entropy(fully_blurred_img)\n",
        "        elif experiments == \"kapis\":\n",
        "            original_img_entropy = estimate_entropy(im_orig)\n",
        "            fully_blurred_img_entropy = estimate_entropy(fully_blurred_img)\n",
        "        else:\n",
        "            original_img_entropy = estimate_image_avg_entropy(im_orig)\n",
        "            fully_blurred_img_entropy = estimate_image_avg_entropy(fully_blurred_img)\n",
        "\n",
        "        pred_func_sic = create_predict_function_softmax(prediction_class, model)\n",
        "        pred = pred_func_sic(im_orig[np.newaxis, ...])\n",
        "        pred_blurred = pred_func_sic(fully_blurred_img[np.newaxis, ...])\n",
        "\n",
        "        if pred > pred_blurred and original_img_entropy > fully_blurred_img_entropy:\n",
        "            baseline = np.zeros(im_orig.shape)\n",
        "\n",
        "            # Compute Guided IG saliency\n",
        "            guided_ig_mask_3d = guided_ig.GetMask(\n",
        "                im_orig, sa.call_model_function, call_model_args, x_steps=25,\n",
        "                x_baseline=baseline, max_dist=1.0, fraction=0.5)\n",
        "            guided_ig_mask_grayscale = saliency.VisualizeImageGrayscale(guided_ig_mask_3d)\n",
        "\n",
        "            # Integrated gradients\n",
        "            integrated_gradients = saliency.IntegratedGradients()\n",
        "            vanilla_mask = saliency.VisualizeImageGrayscale(\n",
        "                integrated_gradients.GetMask(im_orig, sa.call_model_function, call_model_args, x_steps=25,\n",
        "                                             x_baseline=baseline, batch_size=20))\n",
        "            smoothgrad_mask = saliency.VisualizeImageGrayscale(\n",
        "                integrated_gradients.GetSmoothedMask(im_orig, sa.call_model_function, call_model_args, x_steps=25,\n",
        "                                                    x_baseline=baseline, batch_size=20))\n",
        "\n",
        "            # XRAI\n",
        "            xrai_object = saliency.XRAI()\n",
        "            xrai_attributions = xrai_object.GetMask(im_orig, sa.call_model_function, call_model_args, batch_size=20)\n",
        "            if len(xrai_attributions.shape) == 2:\n",
        "                xrai_attributions = np.expand_dims(xrai_attributions, axis=2)\n",
        "\n",
        "            # GradCAM & GradCAM++\n",
        "            gradcam_map = normalize(Gradcam(model, model_modifier=replace2linear, clone=True)(score, im_orig, penultimate_layer=-1))\n",
        "            gradcamplusplus_map = normalize(GradcamPlusPlus(model, model_modifier=replace2linear, clone=True)(score, im_orig, penultimate_layer=-1))\n",
        "            scorecam_map = normalize(Scorecam(model)(score, im_orig, penultimate_layer=-1))\n",
        "\n",
        "            # Compute PIC metrics for SIC and AIC\n",
        "            # [Abbreviated here for brevity; you can call your compute_pic_metric blocks as in your original code]\n",
        "\n",
        "        if len(gig_aic) >= n_samples:\n",
        "            break\n",
        "\n",
        "    return gig_aic, rnd_aic, gig_sic, rnd_sic, \\\n",
        "           vanilla_aic, smoothgrad_aic, vanilla_sic, smoothgrad_sic, \\\n",
        "           xrai_aic, xrai_sic, gradcam_aic, gradcam_sic, \\\n",
        "           gradcamplusplus_aic, gradcamplusplus_sic, scorecam_aic, scorecam_sic\n",
        "\n",
        "\n",
        "# ------------------------------\n",
        "# CLI entry point\n",
        "# ------------------------------\n",
        "@click.command()\n",
        "@click.option(\"--ds\", default=\"BrainTumor\", help=\"Dataset to use for training the model.\")\n",
        "@click.option(\"--experiments\", default=\"base\", help=\"Experiment type (base/kapis/etc).\")\n",
        "@click.option(\"--n_samples\", default=1000, help=\"Number of samples to run the experiment on.\")\n",
        "def main(ds, experiments, n_samples):\n",
        "    dl = DataLoad() if ds == \"BrainTumor\" else DataLoad(datapath=Path(CUSTOM_DATASETS[1]),\n",
        "                                                         outdir=f'{CUSTOM_DATASETS[1]}.npz', segmented=False)\n",
        "    dl.load(masked=True if ds == \"BrainTumor\" else False)\n",
        "    model_indx = 0\n",
        "\n",
        "    results = compute_pic_score(dl, model_indx, masked=True, ds=ds, experiments=experiments, n_samples=n_samples)\n",
        "    print(\"Computation complete, results ready for plotting and CSV export.\")\n",
        "\n",
        "    # [You can now call your plotting and CSV-saving routines as in the original code.]\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "Oq4_CiiMWOBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#=============================\n",
        "# Saliency Analysis Pipeline with PIC & AIC\n",
        "#=============================\n",
        "\n",
        "import logging\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import saliency.core as saliency\n",
        "from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n",
        "from tf_keras_vis.utils.scores import CategoricalScore\n",
        "from tf_keras_vis.utils import normalize\n",
        "from tf_keras_vis.gradcam import Gradcam\n",
        "from tf_keras_vis.gradcam_plus_plus import GradcamPlusPlus\n",
        "from tf_keras_vis.scorecam import Scorecam\n",
        "\n",
        "from data import DataLoad   # Your dataset loader\n",
        "from utils import PackageManager\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "PackageManager.install_and_import('saliency')\n",
        "logging.info(\"Packages imported successfully\")\n",
        "\n",
        "#=============================\n",
        "# Saliency Class\n",
        "#=============================\n",
        "class Saliency:\n",
        "\n",
        "    def __init__(self, model, dl, idx, masked=True, dataset=\"dataset\") -> None:\n",
        "        self.model = model\n",
        "        self.dl = dl\n",
        "        self.idx = idx\n",
        "        self.masked = masked\n",
        "        self.dataset = dataset\n",
        "        self.class_idx_str = 'class_idx_str'\n",
        "\n",
        "    # Model wrapper for saliency computation\n",
        "    def call_model_function(self, images, call_model_args=None, expected_keys=None):\n",
        "        target_class_idx = call_model_args[self.class_idx_str]\n",
        "        images = tf.convert_to_tensor(images)\n",
        "        with tf.GradientTape() as tape:\n",
        "            if expected_keys == [saliency.base.INPUT_OUTPUT_GRADIENTS]:\n",
        "                tape.watch(images)\n",
        "                output_layer = self.model(images)[:, target_class_idx]\n",
        "                gradients = np.array(tape.gradient(output_layer, images))\n",
        "                return {saliency.base.INPUT_OUTPUT_GRADIENTS: gradients}\n",
        "            else:\n",
        "                conv_layer, output_layer = self.model(images)\n",
        "                gradients = np.array(tape.gradient(output_layer, conv_layer))\n",
        "                return {saliency.base.CONVOLUTION_LAYER_VALUES: conv_layer,\n",
        "                        saliency.base.CONVOLUTION_OUTPUT_GRADIENTS: gradients}\n",
        "\n",
        "    @staticmethod\n",
        "    def PreprocessImage(im):\n",
        "        return tf.keras.applications.xception.preprocess_input(im)\n",
        "\n",
        "    @staticmethod\n",
        "    def pick_indices(dl, n=3):\n",
        "        sidx = []\n",
        "        labels = []\n",
        "        while len(labels) < n:\n",
        "            idx = np.random.randint(0, dl.X_.shape[0])\n",
        "            label = dl.y[idx]\n",
        "            if label not in labels:\n",
        "                sidx.append(idx)\n",
        "                labels.append(label)\n",
        "        return sidx\n",
        "\n",
        "    def inference(self, idx):\n",
        "        im = np.expand_dims(self.dl.X_[idx], axis=0)\n",
        "        predictions = self.model(im)\n",
        "        prediction_class = np.argmax(predictions[0])\n",
        "        call_model_args = {self.class_idx_str: prediction_class}\n",
        "        pred_prob = np.round(predictions[0, prediction_class].numpy(), 2)\n",
        "        return predictions, prediction_class, call_model_args, pred_prob\n",
        "\n",
        "    def analyze(self):\n",
        "        data = {'img': [], 'predictions': [], 'prediction_class': [], 'call_model_args': [],\n",
        "                'pred_prob': [], 'actual': [], 'idx': []}\n",
        "        if self.masked:\n",
        "            data.update({'tumorBorder': [], 'original': []})\n",
        "\n",
        "        vizresult = {'Image': [], 'VG': [], 'SmoothGrad': [], 'IG': [], 'XRAI_Full': [],\n",
        "                     'Fast_XRAI': [], 'VIG': [], 'GIG': [], 'Blur_IG': [],\n",
        "                     'GradCAM': [], 'GradCAM++': [], 'ScoreCAM': []}\n",
        "\n",
        "        mycollection = []\n",
        "\n",
        "        for idx in self.idx:\n",
        "            predictions, prediction_class, call_model_args, pred_prob = self.inference(idx)\n",
        "            data['img'].append(self.dl.X_[idx])\n",
        "            data['predictions'].append(predictions)\n",
        "            data['prediction_class'].append(prediction_class)\n",
        "            data['call_model_args'].append(call_model_args)\n",
        "            data['pred_prob'].append(pred_prob)\n",
        "            data['actual'].append(self.dl.y[idx])\n",
        "            data['idx'].append(idx)\n",
        "\n",
        "            if self.masked:\n",
        "                data['tumorBorder'].append(self.dl.Z[idx])\n",
        "                data['original'].append(self.dl.A[idx])\n",
        "                vizresult['Image'].append(self.dl.A[idx])\n",
        "\n",
        "            im = self.dl.X_[idx]\n",
        "\n",
        "            # --- Vanilla Gradient & SmoothGrad ---\n",
        "            gradient_saliency = saliency.GradientSaliency()\n",
        "            vanilla_mask_3d = gradient_saliency.GetMask(im, self.call_model_function, call_model_args)\n",
        "            smoothgrad_mask_3d = gradient_saliency.GetSmoothedMask(im, self.call_model_function, call_model_args)\n",
        "            vizresult['VG'].append(saliency.VisualizeImageGrayscale(vanilla_mask_3d))\n",
        "            vizresult['SmoothGrad'].append(saliency.VisualizeImageGrayscale(smoothgrad_mask_3d))\n",
        "            mycollection.extend([saliency.VisualizeImageGrayscale(vanilla_mask_3d),\n",
        "                                 saliency.VisualizeImageGrayscale(smoothgrad_mask_3d)])\n",
        "\n",
        "            # --- Integrated Gradients & Guided IG ---\n",
        "            ig = saliency.IntegratedGradients()\n",
        "            guided_ig = saliency.GuidedIG()\n",
        "            baseline = np.zeros(im.shape)\n",
        "            ig_mask = ig.GetMask(im, self.call_model_function, call_model_args, x_steps=25, x_baseline=baseline)\n",
        "            guided_ig_mask = guided_ig.GetMask(im, self.call_model_function, call_model_args, x_steps=25, x_baseline=baseline)\n",
        "            mycollection.extend([saliency.VisualizeImageGrayscale(ig_mask),\n",
        "                                 saliency.VisualizeImageGrayscale(guided_ig_mask)])\n",
        "\n",
        "            # --- Blur IG ---\n",
        "            blur_ig = saliency.BlurIG()\n",
        "            blur_mask = blur_ig.GetMask(im, self.call_model_function, call_model_args)\n",
        "            mycollection.append(saliency.VisualizeImageGrayscale(blur_mask))\n",
        "\n",
        "            # --- XRAI ---\n",
        "            xrai = saliency.XRAI()\n",
        "            xrai_mask = xrai.GetMask(im, self.call_model_function, call_model_args)\n",
        "            mycollection.append(xrai_mask)\n",
        "\n",
        "            # --- GradCAM, GradCAM++, ScoreCAM ---\n",
        "            replace2linear = ReplaceToLinear()\n",
        "            score = CategoricalScore([self.dl.y[idx]])\n",
        "            gradcam = Gradcam(self.model, model_modifier=replace2linear, clone=True)\n",
        "            cam = normalize(gradcam(score, im, penultimate_layer=-1))\n",
        "            gradcampp = GradcamPlusPlus(self.model, model_modifier=replace2linear, clone=True)\n",
        "            cam_pp = normalize(gradcampp(score, im, penultimate_layer=-1))\n",
        "            scorecam_obj = Scorecam(self.model)\n",
        "            cam_sc = normalize(scorecam_obj(score, im, penultimate_layer=-1))\n",
        "            mycollection.extend([cam, cam_pp, cam_sc])\n",
        "\n",
        "        return mycollection, data, vizresult\n",
        "\n",
        "    def plot_results(self, mycollection, data, fmt=\"tiff\", show=False):\n",
        "        logging.info(\"Plotting saliency maps...\")\n",
        "        # Use your existing plot_results() logic here\n",
        "        pass\n",
        "\n",
        "#=============================\n",
        "# Main Class: Top-N Models\n",
        "#=============================\n",
        "class Main:\n",
        "\n",
        "    @staticmethod\n",
        "    def load_models(file_path=\"./Data/Evaluation_Results.csv\", n=3):\n",
        "        df = pd.read_csv(file_path).nlargest(n, 'f1_score')\n",
        "        return [df.iloc[i, 1] for i in range(df.shape[0])]\n",
        "\n",
        "#=============================\n",
        "# PIC Metrics & AIC\n",
        "#=============================\n",
        "def compute_pic_aic(model, dl, idx):\n",
        "    \"\"\"\n",
        "    Computes Pixel Importance Curve (PIC) and Accuracy Information Curve (AIC)\n",
        "    \"\"\"\n",
        "    logging.info(\"Computing PIC and AIC metrics...\")\n",
        "    pic_scores = []\n",
        "    aic_scores = []\n",
        "\n",
        "    for i in idx:\n",
        "        im = np.expand_dims(dl.X_[i], axis=0)\n",
        "        pred = model(im)\n",
        "        pred_class = np.argmax(pred[0])\n",
        "        # Simple PIC: fraction of top-k salient pixels\n",
        "        # Example: use GradientSaliency\n",
        "        gs = saliency.GradientSaliency()\n",
        "        mask = gs.GetMask(dl.X_[i], lambda x, **kw: {saliency.base.INPUT_OUTPUT_GRADIENTS: np.array(x)},\n",
        "                          { 'class_idx_str': pred_class })\n",
        "        pic = np.sum(mask) / np.prod(mask.shape)\n",
        "        pic_scores.append(pic)\n",
        "\n",
        "        # Simple AIC: sum of correct predictions weighted by PIC\n",
        "        correct = int(pred_class == dl.y[i])\n",
        "        aic_scores.append(correct * pic)\n",
        "\n",
        "    avg_pic = np.mean(pic_scores)\n",
        "    avg_aic = np.mean(aic_scores)\n",
        "    logging.info(f\"Avg PIC: {avg_pic:.4f}, Avg AIC: {avg_aic:.4f}\")\n",
        "    return avg_pic, avg_aic\n",
        "\n",
        "#=============================\n",
        "# Execution Script\n",
        "#=============================\n",
        "if __name__ == \"__main__\":\n",
        "    dl = DataLoad()\n",
        "    dl.load()  # Load your dataset\n",
        "    idx = Saliency.pick_indices(dl, n=3)\n",
        "\n",
        "    models = Main.load_models(n=2)  # Top 2 models\n",
        "    for m in tqdm(models):\n",
        "        logging.info(f\"Loading model: {m}\")\n",
        "        model = tf.keras.models.load_model(f\"./Models/{m}\")\n",
        "        sa = Saliency(model, dl, idx)\n",
        "        mycollection, data, vizresult = sa.analyze()\n",
        "        sa.plot_results(mycollection, data)\n",
        "\n",
        "        # Compute PIC & AIC for research metrics\n",
        "        pic, aic = compute_pic_aic(model, dl, idx)\n",
        "        logging.info(f\"Saliency analysis completed for {model.name} | PIC={pic:.4f}, AIC={aic:.4f}\")\n"
      ],
      "metadata": {
        "id": "9Utjj798Yotb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/PAIR-code/saliency.git\n",
        "!cd saliency && pip install -e .\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txxW-D3RgLu6",
        "outputId": "94894205-3302-42ea-b89d-66c9be909374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'saliency'...\n",
            "remote: Enumerating objects: 4468, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 4468 (delta 4), reused 3 (delta 3), pack-reused 4452 (from 3)\u001b[K\n",
            "Receiving objects: 100% (4468/4468), 323.89 MiB | 15.16 MiB/s, done.\n",
            "Resolving deltas: 100% (249/249), done.\n",
            "Obtaining file:///content/saliency\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from saliency==0.2.1) (2.0.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from saliency==0.2.1) (0.25.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->saliency==0.2.1) (1.16.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image->saliency==0.2.1) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image->saliency==0.2.1) (11.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->saliency==0.2.1) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->saliency==0.2.1) (2025.10.4)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image->saliency==0.2.1) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->saliency==0.2.1) (0.4)\n",
            "Installing collected packages: saliency\n",
            "  Running setup.py develop for saliency\n",
            "Successfully installed saliency-0.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import logging\n",
        "import pip\n",
        "import importlib\n",
        "import sys\n",
        "import subprocess\n",
        "import logging\n",
        "import cv2\n",
        "\n",
        "class Utils:\n",
        "    \"\"\"\n",
        "        This class impliments utility functions to allow experiment to be carried out successfully. These are custom functions particular to this codebase\n",
        "    \"\"\"\n",
        "    def __init__(self) -> None:\n",
        "        pass\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def resize(x: np.ndarray) -> np.ndarray:\n",
        "        # Assuming x is a grayscale image\n",
        "        resized_img = cv2.resize(x, (225, 225), interpolation=cv2.INTER_LINEAR)\n",
        "        expanded_img = np.expand_dims(resized_img, axis=-1)\n",
        "        return expanded_img\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_samples(X: np.ndarray,y: np.ndarray, Z: np.ndarray, CLASSES: list,idx,figsize=(8,8),save=False, show=True, segmented=False, masked=True, filename=\"Sample\", fmt=\"tiff\"):\n",
        "        \"\"\"\n",
        "            plot_samples plots randomly selected samples from the dataset\n",
        "            :X ndarray of the selected mri slices\n",
        "            : y ndarray of class labels 0 meningioma, 1 glioma, 2 pituitary tumor\n",
        "            : CLASSES is a list of the above mentioned class strings\n",
        "            :idx ndarray of n sample indices\n",
        "        \"\"\"\n",
        "        if(segmented):\n",
        "            fig,axs = plt.subplots(4,4, figsize=figsize)\n",
        "            fig.subplots_adjust(hspace=.5, wspace=.001)\n",
        "            for i, ax in zip(list(range(0,len(idx))),axs.ravel()):\n",
        "                for j in range(Z[idx[i]].shape[0]-1):\n",
        "                    ax.imshow(X[idx[i]])\n",
        "                    ax.scatter(Z[idx[i]][j],  Z[idx[i]][j+1],marker=\".\", color=\"red\", alpha=0.6)\n",
        "                    ax.set_title(CLASSES[y[idx[i]]].capitalize())\n",
        "                    ax.set_axis_off()\n",
        "            if (show):\n",
        "                plt.show()\n",
        "            if(save):\n",
        "                fig.savefig(f'./Figures/{filename}.{fmt}',bbox_inches =\"tight\",dpi=300)\n",
        "            plt.close(fig)\n",
        "        else:\n",
        "            fig,axs = plt.subplots(4,4, figsize=figsize)\n",
        "            fig.subplots_adjust(hspace=.5, wspace=.001)\n",
        "            for i, ax in zip(list(range(0,len(idx))),axs.ravel()):\n",
        "                ax.imshow(np.squeeze(X[idx[i]]), cmap='gray',interpolation='none') # I would add interpolation='none'\n",
        "                if(masked):\n",
        "                 ax.imshow(Z[idx[i]], cmap='jet', alpha=0.4,interpolation='none') # interpolation='none'\n",
        "                ax.set_title(CLASSES[y[idx[i]]].capitalize().replace(\"_\",\" \"))\n",
        "                ax.set_axis_off()\n",
        "            if (show):\n",
        "                plt.show()\n",
        "            if(save):\n",
        "                fig.savefig(f'./Figures/{filename}.{fmt}',bbox_inches =\"tight\",dpi=300)\n",
        "            plt.close(fig)\n",
        "    @staticmethod\n",
        "    def project2D(X_,y,CLASSES,figname='XMRI_TSNE',save=False, show=True,fmt=\"tiff\"):\n",
        "        \"\"\"\n",
        "            The functions takes a standardized dataset X_ and projects it to 2D using TSNE technique for visualization.\n",
        "        \"\"\"\n",
        "        X_embedded = TSNE(n_components=2, learning_rate='auto',init='random').fit_transform(X_.reshape(X_.shape[0],-1).astype('float64'))\n",
        "        logging.info(\"TNSE embedding created successfully. Displaying the 2D projection onto a scatterplot.\")\n",
        "        # #plotting results\n",
        "        fig = plt.figure(1,figsize=(8,4))\n",
        "        scatter = plt.scatter(X_embedded[:,0],X_embedded[:,1], c=list(y))\n",
        "        plt.xlabel(r'$x_1$')\n",
        "        plt.ylabel(r'$x_2$')\n",
        "        plt.legend(handles=scatter.legend_elements()[0], labels=CLASSES,bbox_to_anchor=(1.0, 1.0))\n",
        "        if(save):\n",
        "            plt.savefig(f'./Figures/{figname}.{fmt}', bbox_inches =\"tight\", dpi=300)\n",
        "            logging.info(f\"Figure ./Figures/{figname}.{fmt} written successfully.\")\n",
        "        if(show):\n",
        "            plt.show()\n",
        "        plt.close(fig)\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_confusion_matrix(y_true: np.ndarray, y_pred: np.ndarray,CLASSES: list, save=True, filename='confusion_matrix',figsize=(8,6), fmt=\"tiff\") -> None:\n",
        "        \"\"\"\n",
        "            : y_true the ground truth class labels\n",
        "            : y_pred the predicted class labels\n",
        "            : CLASSES, the list of classes\n",
        "\n",
        "            The function plots a confusion matrix of the model predictions.\n",
        "        \"\"\"\n",
        "        fig = plt.figure(1,figsize=figsize)\n",
        "        CLASSES = [str(i).capitalize() for i in CLASSES]\n",
        "        df_cm = pd.DataFrame(confusion_matrix(y_true, y_pred), index = [i for i in CLASSES],columns = [i for i in CLASSES])\n",
        "        sns.heatmap(df_cm, annot=True, cmap = 'Blues',fmt='g')\n",
        "        if(save):\n",
        "            plt.savefig(f'./Figures/{filename}.{fmt}', bbox_inches =\"tight\", dpi=300)\n",
        "        plt.close(fig)\n",
        "        logging.info(f\"Plot saved successfully to ./Figures/{filename}.{fmt}\")\n",
        "\n",
        "    @staticmethod\n",
        "    def plot_evaluation(dft, save=True, filename=\"Train_Time_Accuracy\", fmt=\"tiff\"):\n",
        "        #@title Plotting Models test performance\n",
        "        # sort df by Count column\n",
        "        dft['model'] = dft['model'].apply(lambda x: str(x).replace(\"_\",\" \").title())\n",
        "        pd_df = dft.sort_values(['f1_score']).reset_index(drop=True)\n",
        "        plt.figure(figsize=(8,6))\n",
        "        # plot barh chart with index as x values\n",
        "        ax = sns.barplot(pd_df.model, pd_df.f1_score)\n",
        "        ax.get_yaxis().set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:,}\".format(np.round(float(x),1))))\n",
        "        ax.set_xlabel(\"Model Architecture\",fontsize=12)\n",
        "        ax.set_ylabel(r\"$F_1$ Score\",fontsize=12)\n",
        "        # add proper Dim values as x labels\n",
        "        ax.set_xticklabels(pd_df.model)\n",
        "        for item in ax.get_xticklabels(): item.set_rotation(90)\n",
        "        for i, v in enumerate(pd_df[\"f1_score\"].iteritems()):\n",
        "            ax.text(i ,v[1], \"{:,}\".format(np.round(v[1],2)), color='b', va ='bottom', rotation=40, fontsize=12)\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'./Figures/{filename}.{fmt}', bbox_inches =\"tight\", dpi=300)\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "    @staticmethod\n",
        "    def create_embedding(model_name: str, X_data: np.ndarray):\n",
        "        logging.info(f\"Loading {model_name.capitalize()} model from ./Models/{model_name}.keras\")\n",
        "        model = tf.keras.models.load_model(f\"./Models/{model_name}.keras\",compile=True)\n",
        "        repmodel  = tf.keras.Model(inputs=model.input, outputs=model.layers[-2].output, name = model.name)\n",
        "        logging.info(\"Model loaded and re-initialized successfully\")\n",
        "        logging.info(f\"Starting inference on {X_data.shape[0]} samples\")\n",
        "        X_hat =  repmodel.predict(X_data)\n",
        "        logging.info(\"Inference completed successfully\")\n",
        "        return X_hat\n",
        "\n",
        "class PackageManager:\n",
        "    def __init__(self) -> None:\n",
        "        pass\n",
        "    @staticmethod\n",
        "    def install_and_import(package: str):\n",
        "        try:\n",
        "            importlib.import_module(package)\n",
        "        except ImportError:\n",
        "            pip.main(['install', package])\n",
        "        finally:\n",
        "            globals()[package] = importlib.import_module(package)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    logging.basicConfig(level=logging.INFO)\n"
      ],
      "metadata": {
        "id": "_-WBEHRtiqVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UQ-yoswnjbvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# Install required packages\n",
        "# ========================\n",
        "!pip install git+https://github.com/PAIR-code/saliency.git\n",
        "!pip install tf-keras-vis\n",
        "\n",
        "# ========================\n",
        "# Standard imports\n",
        "# ========================\n",
        "import PIL.Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import logging\n",
        "\n",
        "# Saliency imports\n",
        "import saliency  # core saliency package\n",
        "from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n",
        "from tf_keras_vis.utils.scores import CategoricalScore\n",
        "from tf_keras_vis.utils import normalize\n",
        "from tf_keras_vis.gradcam import Gradcam\n",
        "from tf_keras_vis.gradcam_plus_plus import GradcamPlusPlus\n",
        "from tf_keras_vis.scorecam import Scorecam\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logging.info(\"Packages imported successfully\")\n",
        "\n",
        "# ========================\n",
        "# Saliency class\n",
        "# ========================\n",
        "class SaliencyAnalysis:\n",
        "    def __init__(self, model, dl, idx, masked=True, dataset_name=\"dataset\"):\n",
        "        self.model = model\n",
        "        self.dl = dl\n",
        "        self.idx = idx\n",
        "        self.masked = masked\n",
        "        self.dataset_name = dataset_name\n",
        "        self.class_idx_str = 'class_idx_str'\n",
        "\n",
        "    # Compute prediction gradients\n",
        "    def call_model_function(self, images, call_model_args=None, expected_keys=None):\n",
        "        target_class_idx = call_model_args[self.class_idx_str]\n",
        "        images = tf.convert_to_tensor(images)\n",
        "        with tf.GradientTape() as tape:\n",
        "            if expected_keys == [saliency.base.INPUT_OUTPUT_GRADIENTS]:\n",
        "                tape.watch(images)\n",
        "                output_layer = self.model(images)\n",
        "                output_layer = output_layer[:, target_class_idx]\n",
        "                gradients = np.array(tape.gradient(output_layer, images))\n",
        "                return {saliency.base.INPUT_OUTPUT_GRADIENTS: gradients}\n",
        "            else:\n",
        "                conv_layer, output_layer = self.model(images)\n",
        "                gradients = np.array(tape.gradient(output_layer, conv_layer))\n",
        "                return {\n",
        "                    saliency.base.CONVOLUTION_LAYER_VALUES: conv_layer,\n",
        "                    saliency.base.CONVOLUTION_OUTPUT_GRADIENTS: gradients\n",
        "                }\n",
        "\n",
        "    @staticmethod\n",
        "    def preprocess_image(im):\n",
        "        return tf.keras.applications.xception.preprocess_input(im)\n",
        "\n",
        "    @staticmethod\n",
        "    def pick_indices(dl, n=3):\n",
        "        sidx = []\n",
        "        labels = []\n",
        "        while len(labels) < n:\n",
        "            idx = np.random.randint(0, dl.X_.shape[0])\n",
        "            label = dl.y[idx]\n",
        "            if label not in labels:\n",
        "                sidx.append(idx)\n",
        "                labels.append(label)\n",
        "        return sidx\n",
        "\n",
        "    def predict(self, im):\n",
        "        im = np.expand_dims(im, axis=0)\n",
        "        predictions = self.model(im)\n",
        "        prediction_class = np.argmax(predictions[0])\n",
        "        call_model_args = {self.class_idx_str: prediction_class}\n",
        "        pred_prob = np.round(predictions[0, prediction_class].numpy(), 2)\n",
        "        return predictions, prediction_class, call_model_args, pred_prob\n",
        "\n",
        "    def inference(self, idx):\n",
        "        im = np.expand_dims(self.dl.X_[idx], axis=0)\n",
        "        predictions = self.model(im)\n",
        "        prediction_class = np.argmax(predictions[0])\n",
        "        call_model_args = {self.class_idx_str: prediction_class}\n",
        "        pred_prob = np.round(predictions[0, prediction_class].numpy(), 2)\n",
        "        return predictions, prediction_class, call_model_args, pred_prob\n",
        "\n",
        "    def analyze(self):\n",
        "        \"\"\"Compute various saliency maps\"\"\"\n",
        "        mycollection = []\n",
        "        data = {'img': [], 'predictions': [], 'prediction_class': [], 'call_model_args': [], 'pred_prob': [], 'actual': [], 'idx': []}\n",
        "\n",
        "        for idx in self.idx:\n",
        "            predictions, prediction_class, call_model_args, pred_prob = self.inference(idx)\n",
        "            data['img'].append(self.dl.X_[idx])\n",
        "            data['predictions'].append(predictions)\n",
        "            data['prediction_class'].append(prediction_class)\n",
        "            data['call_model_args'].append(call_model_args)\n",
        "            data['pred_prob'].append(pred_prob)\n",
        "            data['actual'].append(self.dl.y[idx])\n",
        "            data['idx'].append(idx)\n",
        "\n",
        "            im = self.dl.X_[idx]\n",
        "\n",
        "            # Vanilla gradient saliency\n",
        "            gradient_saliency = saliency.GradientSaliency()\n",
        "            vanilla_mask_3d = gradient_saliency.GetMask(im, self.call_model_function, call_model_args)\n",
        "            smoothgrad_mask_3d = gradient_saliency.GetSmoothedMask(im, self.call_model_function, call_model_args)\n",
        "            vanilla_mask = saliency.VisualizeImageGrayscale(vanilla_mask_3d)\n",
        "            smoothgrad_mask = saliency.VisualizeImageGrayscale(smoothgrad_mask_3d)\n",
        "            mycollection.extend([vanilla_mask, smoothgrad_mask])\n",
        "\n",
        "            # Integrated gradients\n",
        "            integrated_gradients = saliency.IntegratedGradients()\n",
        "            baseline = np.zeros(im.shape)\n",
        "            ig_mask = integrated_gradients.GetMask(im, self.call_model_function, call_model_args, x_steps=25, x_baseline=baseline, batch_size=20)\n",
        "            ig_mask_grayscale = saliency.VisualizeImageGrayscale(ig_mask)\n",
        "            mycollection.append(ig_mask_grayscale)\n",
        "\n",
        "            # Grad-CAM\n",
        "            replace2linear = ReplaceToLinear()\n",
        "            score = CategoricalScore([self.dl.y[idx]])\n",
        "            gradcam = Gradcam(self.model, model_modifier=replace2linear, clone=True)\n",
        "            cam = normalize(gradcam(score, im, penultimate_layer=-1))\n",
        "            mycollection.append(cam)\n",
        "\n",
        "            # Grad-CAM++\n",
        "            gradcampp = GradcamPlusPlus(self.model, model_modifier=replace2linear, clone=True)\n",
        "            campp = normalize(gradcampp(score, im, penultimate_layer=-1))\n",
        "            mycollection.append(campp)\n",
        "\n",
        "            # Score-CAM\n",
        "            scorecam_obj = Scorecam(self.model)\n",
        "            scorecam_map = normalize(scorecam_obj(score, im, penultimate_layer=-1))\n",
        "            mycollection.append(scorecam_map)\n",
        "\n",
        "        return mycollection, data\n",
        "\n",
        "    def plot_results(self, mycollection, data, fmt=\"png\", show=False):\n",
        "        \"\"\"Plot computed saliency maps\"\"\"\n",
        "        num_maps = len(mycollection)\n",
        "        fig, axs = plt.subplots(1, num_maps, figsize=(4*num_maps, 4))\n",
        "        if num_maps == 1:\n",
        "            axs = [axs]\n",
        "        for i in range(num_maps):\n",
        "            axs[i].imshow(np.squeeze(mycollection[i]), cmap='jet')\n",
        "            axs[i].axis('off')\n",
        "        plt.tight_layout()\n",
        "        if show:\n",
        "            plt.show()\n",
        "        plt.savefig(f'{self.dataset_name}_Saliency_Maps.{fmt}', dpi=300)\n",
        "        plt.close(fig)\n",
        "\n",
        "# ========================\n",
        "# Example usage\n",
        "# ========================\n",
        "if __name__ == \"__main__\":\n",
        "    # Example: replace this with your dataset loader\n",
        "    # from data import DataLoad\n",
        "    # dl = DataLoad()\n",
        "    # dl.load()\n",
        "\n",
        "    # Dummy example: random data for testing\n",
        "    class DummyData:\n",
        "        def __init__(self):\n",
        "            self.X_ = np.random.rand(3, 224, 224, 3)\n",
        "            self.y = np.array([0, 1, 2])\n",
        "            self.CLASSES = [\"Class0\", \"Class1\", \"Class2\"]\n",
        "    dl = DummyData()\n",
        "\n",
        "    # Dummy model for testing\n",
        "    model = tf.keras.applications.Xception(weights=None, input_shape=(224,224,3), classes=3)\n",
        "\n",
        "    idx = SaliencyAnalysis.pick_indices(dl, n=3)\n",
        "    sa = SaliencyAnalysis(model, dl, idx)\n",
        "    mycollection, data = sa.analyze()\n",
        "    sa.plot_results(mycollection, data, show=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 716
        },
        "id": "q-9QtVp5ehAj",
        "outputId": "d59eb748-a82f-451f-cf19-ec55073a8d34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/PAIR-code/saliency.git\n",
            "  Cloning https://github.com/PAIR-code/saliency.git to /tmp/pip-req-build-mq3ywj8t\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/PAIR-code/saliency.git /tmp/pip-req-build-mq3ywj8t\n",
            "  Resolved https://github.com/PAIR-code/saliency.git to commit 7b72b673fde6680180befd277c1890d4a9de4b48\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from saliency==0.2.1) (2.0.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from saliency==0.2.1) (0.25.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->saliency==0.2.1) (1.16.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image->saliency==0.2.1) (3.5)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image->saliency==0.2.1) (11.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->saliency==0.2.1) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->saliency==0.2.1) (2025.10.4)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image->saliency==0.2.1) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->saliency==0.2.1) (0.4)\n",
            "Requirement already satisfied: tf-keras-vis in /usr/local/lib/python3.12/dist-packages (0.8.7)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from tf-keras-vis) (1.16.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from tf-keras-vis) (11.3.0)\n",
            "Requirement already satisfied: deprecated in /usr/local/lib/python3.12/dist-packages (from tf-keras-vis) (1.2.18)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.12/dist-packages (from tf-keras-vis) (2.37.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tf-keras-vis) (25.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.12/dist-packages (from deprecated->tf-keras-vis) (1.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from imageio->tf-keras-vis) (2.0.2)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'saliency' has no attribute 'GradientSaliency'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-406448844.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaliencyAnalysis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpick_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaliencyAnalysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     \u001b[0mmycollection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m     \u001b[0msa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmycollection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-406448844.py\u001b[0m in \u001b[0;36manalyze\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;31m# Vanilla gradient saliency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mgradient_saliency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaliency\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientSaliency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0mvanilla_mask_3d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_saliency\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetMask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_model_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_model_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0msmoothgrad_mask_3d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_saliency\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetSmoothedMask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_model_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_model_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'saliency' has no attribute 'GradientSaliency'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qxitq1BbejXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Salincy appliation"
      ],
      "metadata": {
        "id": "k3Xv-6ERej4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# Section 0: Imports & Setup\n",
        "# ==========================================\n",
        "import os\n",
        "import logging\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Saliency imports\n",
        "import saliency.core as saliency\n",
        "from tf_keras_vis.utils.model_modifiers import ReplaceToLinear\n",
        "from tf_keras_vis.utils.scores import CategoricalScore\n",
        "from tf_keras_vis.utils import normalize\n",
        "from tf_keras_vis.gradcam import Gradcam\n",
        "from tf_keras_vis.gradcam_plus_plus import GradcamPlusPlus\n",
        "from tf_keras_vis.scorecam import Scorecam\n",
        "\n",
        "# Custom modules\n",
        "from data import DataLoad\n",
        "from utils import PackageManager\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "PackageManager.install_and_import('saliency')\n",
        "\n",
        "logging.info(\"All packages imported successfully.\")\n",
        "\n",
        "# ==========================================\n",
        "# Section 1: Load Data\n",
        "# ==========================================\n",
        "def load_dataset(data_path):\n",
        "    \"\"\"\n",
        "    Load your dataset using DataLoad class\n",
        "    \"\"\"\n",
        "    dl = DataLoad(data_path=data_path)\n",
        "    dl.load()\n",
        "    logging.info(f\"Dataset loaded. Number of samples: {dl.X_.shape[0]}\")\n",
        "    return dl\n",
        "\n",
        "# ==========================================\n",
        "# Section 2: Load Models\n",
        "# ==========================================\n",
        "def load_top_models(csv_path, models_path, n=2):\n",
        "    \"\"\"\n",
        "    Load top-n models from evaluation CSV\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(csv_path).nlargest(n, 'f1_score')\n",
        "    models = []\n",
        "    for i in range(df.shape[0]):\n",
        "        model_name = df.iloc[i, 1]\n",
        "        logging.info(f\"Loading model: {model_name}\")\n",
        "        model = tf.keras.models.load_model(os.path.join(models_path, model_name))\n",
        "        models.append(model)\n",
        "    return models\n",
        "\n",
        "# ==========================================\n",
        "# Section 3: Saliency Analysis Class\n",
        "# ==========================================\n",
        "class SaliencyAnalysis:\n",
        "    def __init__(self, model, dl, idx, masked=True, dataset_name=\"dataset\"):\n",
        "        self.model = model\n",
        "        self.dl = dl\n",
        "        self.idx = idx\n",
        "        self.masked = masked\n",
        "        self.dataset = dataset_name\n",
        "        self.class_idx_str = 'class_idx_str'\n",
        "\n",
        "    # --- Model call for saliency ---\n",
        "    def call_model_function(self, images, call_model_args=None, expected_keys=None):\n",
        "        target_class_idx = call_model_args[self.class_idx_str]\n",
        "        images = tf.convert_to_tensor(images)\n",
        "        with tf.GradientTape() as tape:\n",
        "            if expected_keys == [saliency.base.INPUT_OUTPUT_GRADIENTS]:\n",
        "                tape.watch(images)\n",
        "                output_layer = self.model(images)\n",
        "                output_layer = output_layer[:, target_class_idx]\n",
        "                gradients = np.array(tape.gradient(output_layer, images))\n",
        "                return {saliency.base.INPUT_OUTPUT_GRADIENTS: gradients}\n",
        "            else:\n",
        "                conv_layer, output_layer = self.model(images)\n",
        "                gradients = np.array(tape.gradient(output_layer, conv_layer))\n",
        "                return {saliency.base.CONVOLUTION_LAYER_VALUES: conv_layer,\n",
        "                        saliency.base.CONVOLUTION_OUTPUT_GRADIENTS: gradients}\n",
        "\n",
        "    # --- Pick random indices ---\n",
        "    @staticmethod\n",
        "    def pick_indices(dl, n=3):\n",
        "        sidx, labels = [], []\n",
        "        while len(labels) < n:\n",
        "            idx = np.random.randint(0, dl.X_.shape[0])\n",
        "            label = dl.y[idx]\n",
        "            if label not in labels:\n",
        "                sidx.append(idx)\n",
        "                labels.append(label)\n",
        "        return sidx\n",
        "\n",
        "    # --- Inference ---\n",
        "    def inference(self, idx):\n",
        "        im = np.expand_dims(self.dl.X_[idx], axis=0)\n",
        "        predictions = self.model(im)\n",
        "        prediction_class = np.argmax(predictions[0])\n",
        "        call_model_args = {self.class_idx_str: prediction_class}\n",
        "        pred_prob = np.round(predictions[0, prediction_class].numpy(), 2)\n",
        "        return predictions, prediction_class, call_model_args, pred_prob\n",
        "\n",
        "    # --- Saliency computation ---\n",
        "    def analyze(self):\n",
        "        logging.info(\"Starting saliency analysis...\")\n",
        "        mycollection, data, vizresult = [], {'img': [], 'predictions': [], 'prediction_class': [], 'call_model_args': [], 'pred_prob': [], 'actual': [], 'idx': []}, {}\n",
        "        for idx in self.idx:\n",
        "            predictions, pred_class, call_model_args, pred_prob = self.inference(idx)\n",
        "            im = self.dl.X_[idx]\n",
        "\n",
        "            data['img'].append(im)\n",
        "            data['predictions'].append(predictions)\n",
        "            data['prediction_class'].append(pred_class)\n",
        "            data['call_model_args'].append(call_model_args)\n",
        "            data['pred_prob'].append(pred_prob)\n",
        "            data['actual'].append(self.dl.y[idx])\n",
        "            data['idx'].append(idx)\n",
        "\n",
        "            # Vanilla Gradient\n",
        "            gradient_saliency = saliency.GradientSaliency()\n",
        "            vanilla_mask_3d = gradient_saliency.GetMask(im, self.call_model_function, call_model_args)\n",
        "            vanilla_mask_grayscale = saliency.VisualizeImageGrayscale(vanilla_mask_3d)\n",
        "            mycollection.append(vanilla_mask_grayscale)\n",
        "\n",
        "            # Integrated Gradients\n",
        "            integrated_gradients = saliency.IntegratedGradients()\n",
        "            baseline = np.zeros(im.shape)\n",
        "            vanilla_ig_mask = integrated_gradients.GetMask(im, self.call_model_function, call_model_args,\n",
        "                                                           x_steps=25, x_baseline=baseline, batch_size=20)\n",
        "            vanilla_ig_grayscale = saliency.VisualizeImageGrayscale(vanilla_ig_mask)\n",
        "            mycollection.append(vanilla_ig_grayscale)\n",
        "\n",
        "            # Grad-CAM\n",
        "            replace2linear = ReplaceToLinear()\n",
        "            score = CategoricalScore([self.dl.y[idx]])\n",
        "            gradcam = Gradcam(self.model, model_modifier=replace2linear, clone=True)\n",
        "            cam = normalize(gradcam(score, im, penultimate_layer=-1))\n",
        "            mycollection.append(cam)\n",
        "\n",
        "        logging.info(\"Saliency analysis completed.\")\n",
        "        return mycollection, data\n",
        "\n",
        "    # --- Plot saliency ---\n",
        "    def plot_saliency(self, mycollection, data, save_path=\"./Figures\"):\n",
        "        os.makedirs(save_path, exist_ok=True)\n",
        "        plt.figure(figsize=(12, 4))\n",
        "        for i, img in enumerate(mycollection):\n",
        "            plt.subplot(1, len(mycollection), i+1)\n",
        "            plt.imshow(img, cmap='jet')\n",
        "            plt.axis('off')\n",
        "        plt.savefig(os.path.join(save_path, f'{self.dataset}_Saliency.png'), dpi=300)\n",
        "        plt.show()\n",
        "\n",
        "# ==========================================\n",
        "# Section 4: PIC and AIC (Optional)\n",
        "# ==========================================\n",
        "# Placeholder for your PIC / AIC computations\n",
        "def compute_pic_aic(predictions, labels):\n",
        "    \"\"\"\n",
        "    Compute Performance Information Curve (PIC) and Accuracy Information Curve (AIC)\n",
        "    Example placeholder, replace with actual implementation\n",
        "    \"\"\"\n",
        "    logging.info(\"Computing PIC and AIC metrics...\")\n",
        "    # Your PIC / AIC computation goes here\n",
        "    pic_curve = np.random.rand(10)  # Dummy\n",
        "    aic_curve = np.random.rand(10)  # Dummy\n",
        "    return pic_curve, aic_curve\n",
        "\n",
        "def plot_pic_aic(pic_curve, aic_curve):\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.plot(pic_curve, label=\"PIC\")\n",
        "    plt.plot(aic_curve, label=\"AIC\")\n",
        "    plt.title(\"PIC & AIC Curves\")\n",
        "    plt.xlabel(\"Threshold\")\n",
        "    plt.ylabel(\"Metric\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# ==========================================\n",
        "# Section 5: Main Execution\n",
        "# ==========================================\n",
        "if __name__ == \"__main__\":\n",
        "    # Paths to your data and models\n",
        "    DATA_PATH =  '/content/drive/MyDrive/Signal Processing ML/Audio Mel-spectrogram/Study sites/Port of St Francies/Test/'\n",
        "    MODELS_PATH = '/content/drive/MyDrive/Signal Processing ML/Audio Mel-spectrogram/Study sites/Port of St Francies/Models_LR1_0.001_Reg_0.01/'\n",
        "\n",
        "\n",
        "    CSV_PATH =  '/content/drive/MyDrive/Signal Processing ML/Audio Mel-spectrogram/Study sites/Port of St Francies/'\n",
        "\n",
        "    # Load data\n",
        "    dl = load_dataset(DATA_PATH)\n",
        "\n",
        "    # Pick sample indices for saliency\n",
        "    idx = SaliencyAnalysis.pick_indices(dl, n=3)\n",
        "\n",
        "    # Load top models\n",
        "    models = load_top_models(CSV_PATH, MODELS_PATH, n=2)\n",
        "\n",
        "    for model in models:\n",
        "        # Saliency analysis\n",
        "        sa = SaliencyAnalysis(model, dl, idx)\n",
        "        mycollection, data = sa.analyze()\n",
        "        sa.plot_saliency(mycollection, data)\n",
        "\n",
        "        # PIC & AIC\n",
        "        pic_curve, aic_curve = compute_pic_aic(data['predictions'], data['actual'])\n",
        "        plot_pic_aic(pic_curve, aic_curve)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "g1Xv55P0eDG7",
        "outputId": "e0110cc6-7d44-4eae-9900-de85727f6fb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'data'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1290093161.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Custom modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPackageManager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "xZt8kucHo286"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoegwRbbqPhf",
        "outputId": "e391ecc7-90e6-450e-abd0-33541c05fea1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                                  Version\n",
            "---------------------------------------- --------------------\n",
            "absl-py                                  1.4.0\n",
            "absolufy-imports                         0.3.1\n",
            "accelerate                               1.10.1\n",
            "aiofiles                                 24.1.0\n",
            "aiohappyeyeballs                         2.6.1\n",
            "aiohttp                                  3.13.0\n",
            "aiosignal                                1.4.0\n",
            "alabaster                                1.0.0\n",
            "albucore                                 0.0.24\n",
            "albumentations                           2.0.8\n",
            "ale-py                                   0.11.2\n",
            "alembic                                  1.17.0\n",
            "altair                                   5.5.0\n",
            "annotated-types                          0.7.0\n",
            "antlr4-python3-runtime                   4.9.3\n",
            "anyio                                    4.11.0\n",
            "anywidget                                0.9.18\n",
            "argon2-cffi                              25.1.0\n",
            "argon2-cffi-bindings                     25.1.0\n",
            "array_record                             0.8.1\n",
            "arrow                                    1.3.0\n",
            "arviz                                    0.22.0\n",
            "astropy                                  7.1.1\n",
            "astropy-iers-data                        0.2025.10.13.0.37.17\n",
            "astunparse                               1.6.3\n",
            "atpublic                                 5.1\n",
            "attrs                                    25.4.0\n",
            "audioread                                3.0.1\n",
            "Authlib                                  1.6.5\n",
            "autograd                                 1.8.0\n",
            "babel                                    2.17.0\n",
            "backcall                                 0.2.0\n",
            "beartype                                 0.22.2\n",
            "beautifulsoup4                           4.13.5\n",
            "betterproto                              2.0.0b6\n",
            "bigframes                                2.24.0\n",
            "bigquery-magics                          0.10.3\n",
            "bleach                                   6.2.0\n",
            "blinker                                  1.9.0\n",
            "blis                                     1.3.0\n",
            "blobfile                                 3.1.0\n",
            "blosc2                                   3.10.1\n",
            "bokeh                                    3.7.3\n",
            "Bottleneck                               1.4.2\n",
            "bqplot                                   0.12.45\n",
            "branca                                   0.8.2\n",
            "Brotli                                   1.1.0\n",
            "build                                    1.3.0\n",
            "CacheControl                             0.14.3\n",
            "cachetools                               5.5.2\n",
            "catalogue                                2.0.10\n",
            "certifi                                  2025.10.5\n",
            "cffi                                     2.0.0\n",
            "chardet                                  5.2.0\n",
            "charset-normalizer                       3.4.4\n",
            "chex                                     0.1.90\n",
            "clarabel                                 0.11.1\n",
            "click                                    8.3.0\n",
            "cloudpathlib                             0.23.0\n",
            "cloudpickle                              3.1.1\n",
            "cmake                                    3.31.6\n",
            "cmdstanpy                                1.2.5\n",
            "colorcet                                 3.1.0\n",
            "colorlover                               0.3.0\n",
            "colour                                   0.1.5\n",
            "community                                1.0.0b1\n",
            "confection                               0.1.5\n",
            "cons                                     0.4.7\n",
            "contourpy                                1.3.3\n",
            "cramjam                                  2.11.0\n",
            "cryptography                             43.0.3\n",
            "cuda-python                              12.6.2.post1\n",
            "cudf-cu12                                25.6.0\n",
            "cudf-polars-cu12                         25.6.0\n",
            "cufflinks                                0.17.3\n",
            "cuml-cu12                                25.6.0\n",
            "cupy-cuda12x                             13.3.0\n",
            "curl_cffi                                0.13.0\n",
            "cuvs-cu12                                25.6.1\n",
            "cvxopt                                   1.3.2\n",
            "cvxpy                                    1.6.7\n",
            "cycler                                   0.12.1\n",
            "cyipopt                                  1.5.0\n",
            "cymem                                    2.0.11\n",
            "Cython                                   3.0.12\n",
            "dask                                     2025.5.0\n",
            "dask-cuda                                25.6.0\n",
            "dask-cudf-cu12                           25.6.0\n",
            "dataproc-spark-connect                   0.8.3\n",
            "datasets                                 4.0.0\n",
            "db-dtypes                                1.4.3\n",
            "dbus-python                              1.2.18\n",
            "debugpy                                  1.8.15\n",
            "decorator                                4.4.2\n",
            "defusedxml                               0.7.1\n",
            "diffusers                                0.35.2\n",
            "dill                                     0.3.8\n",
            "distributed                              2025.5.0\n",
            "distributed-ucxx-cu12                    0.44.0\n",
            "distro                                   1.9.0\n",
            "dlib                                     19.24.6\n",
            "dm-tree                                  0.1.9\n",
            "docstring_parser                         0.17.0\n",
            "docutils                                 0.21.2\n",
            "dopamine_rl                              4.1.2\n",
            "duckdb                                   1.3.2\n",
            "earthengine-api                          1.5.24\n",
            "easydict                                 1.13\n",
            "editdistance                             0.8.1\n",
            "eerepr                                   0.1.2\n",
            "einops                                   0.8.1\n",
            "en_core_web_sm                           3.8.0\n",
            "entrypoints                              0.4\n",
            "et_xmlfile                               2.0.0\n",
            "etils                                    1.13.0\n",
            "etuples                                  0.3.10\n",
            "Farama-Notifications                     0.0.4\n",
            "fastai                                   2.8.4\n",
            "fastapi                                  0.119.0\n",
            "fastcore                                 1.8.12\n",
            "fastdownload                             0.0.7\n",
            "fastjsonschema                           2.21.2\n",
            "fastprogress                             1.0.3\n",
            "fastrlock                                0.8.3\n",
            "fasttransform                            0.0.2\n",
            "ffmpy                                    0.6.3\n",
            "filelock                                 3.20.0\n",
            "firebase-admin                           6.9.0\n",
            "Flask                                    3.1.2\n",
            "flatbuffers                              25.9.23\n",
            "flax                                     0.10.6\n",
            "folium                                   0.20.0\n",
            "fonttools                                4.60.1\n",
            "fqdn                                     1.5.1\n",
            "frozendict                               2.4.6\n",
            "frozenlist                               1.8.0\n",
            "fsspec                                   2025.3.0\n",
            "future                                   1.0.0\n",
            "gast                                     0.6.0\n",
            "gcsfs                                    2025.3.0\n",
            "GDAL                                     3.8.4\n",
            "gdown                                    5.2.0\n",
            "geemap                                   0.35.3\n",
            "geocoder                                 1.38.1\n",
            "geographiclib                            2.1\n",
            "geopandas                                1.1.1\n",
            "geopy                                    2.4.1\n",
            "gin-config                               0.5.0\n",
            "gitdb                                    4.0.12\n",
            "GitPython                                3.1.45\n",
            "glob2                                    0.7\n",
            "google                                   2.0.3\n",
            "google-adk                               1.16.0\n",
            "google-ai-generativelanguage             0.6.15\n",
            "google-api-core                          2.26.0\n",
            "google-api-python-client                 2.184.0\n",
            "google-auth                              2.38.0\n",
            "google-auth-httplib2                     0.2.0\n",
            "google-auth-oauthlib                     1.2.2\n",
            "google-cloud-aiplatform                  1.120.0\n",
            "google-cloud-appengine-logging           1.6.2\n",
            "google-cloud-audit-log                   0.3.3\n",
            "google-cloud-bigquery                    3.38.0\n",
            "google-cloud-bigquery-connection         1.18.3\n",
            "google-cloud-bigquery-storage            2.33.1\n",
            "google-cloud-bigtable                    2.33.0\n",
            "google-cloud-core                        2.4.3\n",
            "google-cloud-dataproc                    5.22.0\n",
            "google-cloud-datastore                   2.21.0\n",
            "google-cloud-discoveryengine             0.13.12\n",
            "google-cloud-firestore                   2.21.0\n",
            "google-cloud-functions                   1.20.4\n",
            "google-cloud-language                    2.17.2\n",
            "google-cloud-logging                     3.12.1\n",
            "google-cloud-monitoring                  2.28.0\n",
            "google-cloud-resource-manager            1.14.2\n",
            "google-cloud-secret-manager              2.25.0\n",
            "google-cloud-spanner                     3.58.0\n",
            "google-cloud-speech                      2.33.0\n",
            "google-cloud-storage                     2.19.0\n",
            "google-cloud-trace                       1.16.2\n",
            "google-cloud-translate                   3.21.1\n",
            "google-colab                             1.0.0\n",
            "google-crc32c                            1.7.1\n",
            "google-genai                             1.44.0\n",
            "google-generativeai                      0.8.5\n",
            "google-pasta                             0.2.0\n",
            "google-resumable-media                   2.7.2\n",
            "googleapis-common-protos                 1.70.0\n",
            "googledrivedownloader                    1.1.0\n",
            "gradio                                   5.49.1\n",
            "gradio_client                            1.13.3\n",
            "graphviz                                 0.21\n",
            "greenlet                                 3.2.4\n",
            "groovy                                   0.1.2\n",
            "grpc-google-iam-v1                       0.14.2\n",
            "grpc-interceptor                         0.15.4\n",
            "grpcio                                   1.75.1\n",
            "grpcio-status                            1.71.2\n",
            "grpclib                                  0.4.8\n",
            "gspread                                  6.2.1\n",
            "gspread-dataframe                        4.0.0\n",
            "gym                                      0.25.2\n",
            "gym-notices                              0.1.0\n",
            "gymnasium                                1.2.1\n",
            "h11                                      0.16.0\n",
            "h2                                       4.3.0\n",
            "h5netcdf                                 1.6.4\n",
            "h5py                                     3.15.0\n",
            "hdbscan                                  0.8.40\n",
            "hf_transfer                              0.1.9\n",
            "hf-xet                                   1.1.10\n",
            "highspy                                  1.11.0\n",
            "holidays                                 0.82\n",
            "holoviews                                1.21.0\n",
            "hpack                                    4.1.0\n",
            "html5lib                                 1.1\n",
            "httpcore                                 1.0.9\n",
            "httpimport                               1.4.1\n",
            "httplib2                                 0.31.0\n",
            "httpx                                    0.28.1\n",
            "httpx-sse                                0.4.3\n",
            "huggingface-hub                          0.35.3\n",
            "humanize                                 4.13.0\n",
            "hyperframe                               6.1.0\n",
            "hyperopt                                 0.2.7\n",
            "ibis-framework                           9.5.0\n",
            "idna                                     3.11\n",
            "imageio                                  2.37.0\n",
            "imageio-ffmpeg                           0.6.0\n",
            "imagesize                                1.4.1\n",
            "imbalanced-learn                         0.14.0\n",
            "immutabledict                            4.2.2\n",
            "importlib_metadata                       8.7.0\n",
            "importlib_resources                      6.5.2\n",
            "imutils                                  0.5.4\n",
            "inflect                                  7.5.0\n",
            "iniconfig                                2.1.0\n",
            "intel-cmplr-lib-ur                       2025.2.1\n",
            "intel-openmp                             2025.2.1\n",
            "ipyevents                                2.0.4\n",
            "ipyfilechooser                           0.6.0\n",
            "ipykernel                                6.17.1\n",
            "ipyleaflet                               0.20.0\n",
            "ipyparallel                              8.8.0\n",
            "ipython                                  7.34.0\n",
            "ipython-genutils                         0.2.0\n",
            "ipython-sql                              0.5.0\n",
            "ipytree                                  0.2.2\n",
            "ipywidgets                               7.7.1\n",
            "isoduration                              20.11.0\n",
            "itsdangerous                             2.2.0\n",
            "jaraco.classes                           3.4.0\n",
            "jaraco.context                           6.0.1\n",
            "jaraco.functools                         4.3.0\n",
            "jax                                      0.5.3\n",
            "jax-cuda12-pjrt                          0.5.3\n",
            "jax-cuda12-plugin                        0.5.3\n",
            "jaxlib                                   0.5.3\n",
            "jeepney                                  0.9.0\n",
            "jieba                                    0.42.1\n",
            "Jinja2                                   3.1.6\n",
            "jiter                                    0.11.0\n",
            "joblib                                   1.5.2\n",
            "jsonpatch                                1.33\n",
            "jsonpickle                               4.1.1\n",
            "jsonpointer                              3.0.0\n",
            "jsonschema                               4.25.1\n",
            "jsonschema-specifications                2025.9.1\n",
            "jupyter_client                           7.4.9\n",
            "jupyter-console                          6.6.3\n",
            "jupyter_core                             5.8.1\n",
            "jupyter-events                           0.12.0\n",
            "jupyter_kernel_gateway                   2.5.2\n",
            "jupyter-leaflet                          0.20.0\n",
            "jupyter_server                           2.14.0\n",
            "jupyter_server_terminals                 0.5.3\n",
            "jupyterlab_pygments                      0.3.0\n",
            "jupyterlab_widgets                       3.0.15\n",
            "jupytext                                 1.17.3\n",
            "kaggle                                   1.7.4.5\n",
            "kagglehub                                0.3.13\n",
            "keras                                    3.10.0\n",
            "keras-hub                                0.21.1\n",
            "keras-nlp                                0.21.1\n",
            "keyring                                  25.6.0\n",
            "keyrings.google-artifactregistry-auth    1.1.2\n",
            "kiwisolver                               1.4.9\n",
            "langchain                                0.3.27\n",
            "langchain-core                           0.3.79\n",
            "langchain-text-splitters                 0.3.11\n",
            "langcodes                                3.5.0\n",
            "langsmith                                0.4.35\n",
            "language_data                            1.3.0\n",
            "lark                                     1.3.0\n",
            "launchpadlib                             1.10.16\n",
            "lazr.restfulclient                       0.14.4\n",
            "lazr.uri                                 1.0.6\n",
            "lazy_loader                              0.4\n",
            "libclang                                 18.1.1\n",
            "libcudf-cu12                             25.6.0\n",
            "libcugraph-cu12                          25.6.0\n",
            "libcuml-cu12                             25.6.0\n",
            "libcuvs-cu12                             25.6.1\n",
            "libkvikio-cu12                           25.6.0\n",
            "libpysal                                 4.13.0\n",
            "libraft-cu12                             25.6.0\n",
            "librmm-cu12                              25.6.0\n",
            "librosa                                  0.11.0\n",
            "libucx-cu12                              1.18.1\n",
            "libucxx-cu12                             0.44.0\n",
            "lightgbm                                 4.6.0\n",
            "linkify-it-py                            2.0.3\n",
            "llvmlite                                 0.43.0\n",
            "locket                                   1.0.0\n",
            "logical-unification                      0.4.6\n",
            "lxml                                     5.4.0\n",
            "Mako                                     1.3.10\n",
            "marisa-trie                              1.3.1\n",
            "Markdown                                 3.9\n",
            "markdown-it-py                           4.0.0\n",
            "MarkupSafe                               3.0.3\n",
            "matplotlib                               3.10.0\n",
            "matplotlib-inline                        0.1.7\n",
            "matplotlib-venn                          1.1.2\n",
            "mcp                                      1.17.0\n",
            "mdit-py-plugins                          0.5.0\n",
            "mdurl                                    0.1.2\n",
            "miniKanren                               1.0.5\n",
            "missingno                                0.5.2\n",
            "mistune                                  3.1.4\n",
            "mizani                                   0.13.5\n",
            "mkl                                      2025.2.0\n",
            "ml_dtypes                                0.5.3\n",
            "mlxtend                                  0.23.4\n",
            "more-itertools                           10.8.0\n",
            "moviepy                                  1.0.3\n",
            "mpmath                                   1.3.0\n",
            "msgpack                                  1.1.2\n",
            "multidict                                6.7.0\n",
            "multipledispatch                         1.0.0\n",
            "multiprocess                             0.70.16\n",
            "multitasking                             0.0.12\n",
            "murmurhash                               1.0.13\n",
            "music21                                  9.3.0\n",
            "namex                                    0.1.0\n",
            "narwhals                                 2.8.0\n",
            "natsort                                  8.4.0\n",
            "nbclassic                                1.3.3\n",
            "nbclient                                 0.10.2\n",
            "nbconvert                                7.16.6\n",
            "nbformat                                 5.10.4\n",
            "ndindex                                  1.10.0\n",
            "nest-asyncio                             1.6.0\n",
            "networkx                                 3.5\n",
            "nibabel                                  5.3.2\n",
            "nltk                                     3.9.1\n",
            "notebook                                 6.5.7\n",
            "notebook_shim                            0.2.4\n",
            "numba                                    0.60.0\n",
            "numba-cuda                               0.11.0\n",
            "numexpr                                  2.14.1\n",
            "numpy                                    2.0.2\n",
            "nvidia-cublas-cu12                       12.6.4.1\n",
            "nvidia-cuda-cupti-cu12                   12.6.80\n",
            "nvidia-cuda-nvcc-cu12                    12.5.82\n",
            "nvidia-cuda-nvrtc-cu12                   12.6.77\n",
            "nvidia-cuda-runtime-cu12                 12.6.77\n",
            "nvidia-cudnn-cu12                        9.10.2.21\n",
            "nvidia-cufft-cu12                        11.3.0.4\n",
            "nvidia-cufile-cu12                       1.11.1.6\n",
            "nvidia-curand-cu12                       10.3.7.77\n",
            "nvidia-cusolver-cu12                     11.7.1.2\n",
            "nvidia-cusparse-cu12                     12.5.4.2\n",
            "nvidia-cusparselt-cu12                   0.7.1\n",
            "nvidia-ml-py                             12.575.51\n",
            "nvidia-nccl-cu12                         2.27.3\n",
            "nvidia-nvjitlink-cu12                    12.6.85\n",
            "nvidia-nvtx-cu12                         12.6.77\n",
            "nvtx                                     0.2.13\n",
            "nx-cugraph-cu12                          25.6.0\n",
            "oauth2client                             4.1.3\n",
            "oauthlib                                 3.3.1\n",
            "omegaconf                                2.3.0\n",
            "openai                                   1.109.1\n",
            "opencv-contrib-python                    4.12.0.88\n",
            "opencv-python                            4.12.0.88\n",
            "opencv-python-headless                   4.12.0.88\n",
            "openpyxl                                 3.1.5\n",
            "opentelemetry-api                        1.37.0\n",
            "opentelemetry-exporter-gcp-logging       1.10.0a0\n",
            "opentelemetry-exporter-gcp-monitoring    1.10.0a0\n",
            "opentelemetry-exporter-gcp-trace         1.10.0\n",
            "opentelemetry-exporter-otlp-proto-common 1.37.0\n",
            "opentelemetry-exporter-otlp-proto-http   1.37.0\n",
            "opentelemetry-proto                      1.37.0\n",
            "opentelemetry-resourcedetector-gcp       1.10.0a0\n",
            "opentelemetry-sdk                        1.37.0\n",
            "opentelemetry-semantic-conventions       0.58b0\n",
            "opt_einsum                               3.4.0\n",
            "optax                                    0.2.6\n",
            "optree                                   0.17.0\n",
            "orbax-checkpoint                         0.11.24\n",
            "orjson                                   3.11.3\n",
            "osqp                                     1.0.4\n",
            "overrides                                7.7.0\n",
            "packaging                                25.0\n",
            "pandas                                   2.2.2\n",
            "pandas-datareader                        0.10.0\n",
            "pandas-gbq                               0.29.2\n",
            "pandas-stubs                             2.2.2.240909\n",
            "pandocfilters                            1.5.1\n",
            "panel                                    1.8.2\n",
            "param                                    2.2.1\n",
            "parso                                    0.8.5\n",
            "parsy                                    2.2\n",
            "partd                                    1.4.2\n",
            "patsy                                    1.0.1\n",
            "peewee                                   3.18.2\n",
            "peft                                     0.17.1\n",
            "pexpect                                  4.9.0\n",
            "pickleshare                              0.7.5\n",
            "pillow                                   11.3.0\n",
            "pip                                      24.1.2\n",
            "platformdirs                             4.5.0\n",
            "plotly                                   5.24.1\n",
            "plotnine                                 0.14.5\n",
            "pluggy                                   1.6.0\n",
            "plum-dispatch                            2.5.8\n",
            "ply                                      3.11\n",
            "polars                                   1.25.2\n",
            "pooch                                    1.8.2\n",
            "portpicker                               1.5.2\n",
            "preshed                                  3.0.10\n",
            "prettytable                              3.16.0\n",
            "proglog                                  0.1.12\n",
            "progressbar2                             4.5.0\n",
            "prometheus_client                        0.23.1\n",
            "promise                                  2.3\n",
            "prompt_toolkit                           3.0.52\n",
            "propcache                                0.4.1\n",
            "prophet                                  1.1.7\n",
            "proto-plus                               1.26.1\n",
            "protobuf                                 5.29.5\n",
            "psutil                                   5.9.5\n",
            "psycopg2                                 2.9.11\n",
            "psygnal                                  0.14.2\n",
            "ptyprocess                               0.7.0\n",
            "py-cpuinfo                               9.0.0\n",
            "py4j                                     0.10.9.7\n",
            "pyarrow                                  18.1.0\n",
            "pyasn1                                   0.6.1\n",
            "pyasn1_modules                           0.4.2\n",
            "pycairo                                  1.28.0\n",
            "pycocotools                              2.0.10\n",
            "pycparser                                2.23\n",
            "pycryptodomex                            3.23.0\n",
            "pydantic                                 2.11.10\n",
            "pydantic_core                            2.33.2\n",
            "pydantic-settings                        2.11.0\n",
            "pydata-google-auth                       1.9.1\n",
            "pydot                                    3.0.4\n",
            "pydotplus                                2.0.2\n",
            "PyDrive2                                 1.21.3\n",
            "pydub                                    0.25.1\n",
            "pyerfa                                   2.0.1.5\n",
            "pygame                                   2.6.1\n",
            "pygit2                                   1.18.2\n",
            "Pygments                                 2.19.2\n",
            "PyGObject                                3.42.0\n",
            "PyJWT                                    2.10.1\n",
            "pylibcudf-cu12                           25.6.0\n",
            "pylibcugraph-cu12                        25.6.0\n",
            "pylibraft-cu12                           25.6.0\n",
            "pymc                                     5.25.1\n",
            "pynndescent                              0.5.13\n",
            "pynvjitlink-cu12                         0.7.0\n",
            "pynvml                                   12.0.0\n",
            "pyogrio                                  0.11.1\n",
            "pyomo                                    6.9.4\n",
            "PyOpenGL                                 3.1.10\n",
            "pyOpenSSL                                24.2.1\n",
            "pyparsing                                3.2.5\n",
            "pyperclip                                1.11.0\n",
            "pyproj                                   3.7.2\n",
            "pyproject_hooks                          1.2.0\n",
            "pyshp                                    3.0.2.post1\n",
            "PySocks                                  1.7.1\n",
            "pyspark                                  3.5.1\n",
            "pytensor                                 2.31.7\n",
            "pytest                                   8.4.2\n",
            "python-apt                               0.0.0\n",
            "python-box                               7.3.2\n",
            "python-dateutil                          2.9.0.post0\n",
            "python-dotenv                            1.1.1\n",
            "python-json-logger                       4.0.0\n",
            "python-louvain                           0.16\n",
            "python-multipart                         0.0.20\n",
            "python-slugify                           8.0.4\n",
            "python-snappy                            0.7.3\n",
            "python-utils                             3.9.1\n",
            "pytz                                     2025.2\n",
            "pyviz_comms                              3.0.6\n",
            "PyWavelets                               1.9.0\n",
            "PyYAML                                   6.0.3\n",
            "pyzmq                                    26.2.1\n",
            "raft-dask-cu12                           25.6.0\n",
            "rapids-dask-dependency                   25.6.0\n",
            "rapids-logger                            0.1.19\n",
            "ratelim                                  0.1.6\n",
            "referencing                              0.37.0\n",
            "regex                                    2024.11.6\n",
            "requests                                 2.32.4\n",
            "requests-oauthlib                        2.0.0\n",
            "requests-toolbelt                        1.0.0\n",
            "requirements-parser                      0.9.0\n",
            "rfc3339-validator                        0.1.4\n",
            "rfc3986-validator                        0.1.1\n",
            "rfc3987-syntax                           1.1.0\n",
            "rich                                     13.9.4\n",
            "rmm-cu12                                 25.6.0\n",
            "roman-numerals-py                        3.1.0\n",
            "rpds-py                                  0.27.1\n",
            "rpy2                                     3.5.17\n",
            "rsa                                      4.9.1\n",
            "ruff                                     0.14.0\n",
            "safehttpx                                0.1.6\n",
            "safetensors                              0.6.2\n",
            "scikit-image                             0.25.2\n",
            "scikit-learn                             1.6.1\n",
            "scipy                                    1.16.2\n",
            "scooby                                   0.10.2\n",
            "scs                                      3.2.9\n",
            "seaborn                                  0.13.2\n",
            "SecretStorage                            3.4.0\n",
            "semantic-version                         2.10.0\n",
            "Send2Trash                               1.8.3\n",
            "sentence-transformers                    5.1.1\n",
            "sentencepiece                            0.2.1\n",
            "sentry-sdk                               2.41.0\n",
            "setuptools                               75.2.0\n",
            "shap                                     0.49.1\n",
            "shapely                                  2.1.2\n",
            "shellingham                              1.5.4\n",
            "simple-parsing                           0.1.7\n",
            "simplejson                               3.20.2\n",
            "simsimd                                  6.5.3\n",
            "six                                      1.17.0\n",
            "sklearn-pandas                           2.2.0\n",
            "slicer                                   0.0.8\n",
            "smart_open                               7.3.1\n",
            "smmap                                    5.0.2\n",
            "sniffio                                  1.3.1\n",
            "snowballstemmer                          3.0.1\n",
            "sortedcontainers                         2.4.0\n",
            "soundfile                                0.13.1\n",
            "soupsieve                                2.8\n",
            "soxr                                     1.0.0\n",
            "spacy                                    3.8.7\n",
            "spacy-legacy                             3.0.12\n",
            "spacy-loggers                            1.0.5\n",
            "spanner-graph-notebook                   1.1.8\n",
            "Sphinx                                   8.2.3\n",
            "sphinxcontrib-applehelp                  2.0.0\n",
            "sphinxcontrib-devhelp                    2.0.0\n",
            "sphinxcontrib-htmlhelp                   2.1.0\n",
            "sphinxcontrib-jsmath                     1.0.1\n",
            "sphinxcontrib-qthelp                     2.0.0\n",
            "sphinxcontrib-serializinghtml            2.0.0\n",
            "SQLAlchemy                               2.0.44\n",
            "sqlalchemy-spanner                       1.17.0\n",
            "sqlglot                                  25.20.2\n",
            "sqlparse                                 0.5.3\n",
            "srsly                                    2.5.1\n",
            "sse-starlette                            3.0.2\n",
            "stanio                                   0.5.1\n",
            "starlette                                0.48.0\n",
            "statsmodels                              0.14.5\n",
            "stringzilla                              4.2.1\n",
            "stumpy                                   1.13.0\n",
            "sympy                                    1.13.3\n",
            "tables                                   3.10.2\n",
            "tabulate                                 0.9.0\n",
            "tbb                                      2022.2.0\n",
            "tblib                                    3.1.0\n",
            "tcmlib                                   1.4.0\n",
            "tenacity                                 8.5.0\n",
            "tensorboard                              2.19.0\n",
            "tensorboard-data-server                  0.7.2\n",
            "tensorflow                               2.19.0\n",
            "tensorflow-datasets                      4.9.9\n",
            "tensorflow_decision_forests              1.12.0\n",
            "tensorflow-hub                           0.16.1\n",
            "tensorflow-metadata                      1.17.2\n",
            "tensorflow-probability                   0.25.0\n",
            "tensorflow-text                          2.19.0\n",
            "tensorstore                              0.1.78\n",
            "termcolor                                3.1.0\n",
            "terminado                                0.18.1\n",
            "text-unidecode                           1.3\n",
            "textblob                                 0.19.0\n",
            "tf_keras                                 2.19.0\n",
            "tf-slim                                  1.1.0\n",
            "thinc                                    8.3.6\n",
            "threadpoolctl                            3.6.0\n",
            "tifffile                                 2025.10.4\n",
            "tiktoken                                 0.12.0\n",
            "timm                                     1.0.20\n",
            "tinycss2                                 1.4.0\n",
            "tokenizers                               0.22.1\n",
            "toml                                     0.10.2\n",
            "tomlkit                                  0.13.3\n",
            "toolz                                    0.12.1\n",
            "torch                                    2.8.0+cu126\n",
            "torchao                                  0.10.0\n",
            "torchaudio                               2.8.0+cu126\n",
            "torchdata                                0.11.0\n",
            "torchsummary                             1.5.1\n",
            "torchtune                                0.6.1\n",
            "torchvision                              0.23.0+cu126\n",
            "tornado                                  6.5.1\n",
            "tqdm                                     4.67.1\n",
            "traitlets                                5.7.1\n",
            "traittypes                               0.2.1\n",
            "transformers                             4.57.1\n",
            "treelite                                 4.4.1\n",
            "treescope                                0.1.10\n",
            "triton                                   3.4.0\n",
            "tsfresh                                  0.21.1\n",
            "tweepy                                   4.16.0\n",
            "typeguard                                4.4.4\n",
            "typer                                    0.19.2\n",
            "types-python-dateutil                    2.9.0.20251008\n",
            "types-pytz                               2025.2.0.20250809\n",
            "types-setuptools                         80.9.0.20250822\n",
            "typing_extensions                        4.15.0\n",
            "typing-inspection                        0.4.2\n",
            "tzdata                                   2025.2\n",
            "tzlocal                                  5.3.1\n",
            "uc-micro-py                              1.0.3\n",
            "ucx-py-cu12                              0.44.0\n",
            "ucxx-cu12                                0.44.0\n",
            "umap-learn                               0.5.9.post2\n",
            "umf                                      0.11.0\n",
            "uri-template                             1.3.0\n",
            "uritemplate                              4.2.0\n",
            "urllib3                                  2.5.0\n",
            "uvicorn                                  0.37.0\n",
            "vega-datasets                            0.9.0\n",
            "wadllib                                  1.3.6\n",
            "wandb                                    0.22.2\n",
            "wasabi                                   1.1.3\n",
            "watchdog                                 6.0.0\n",
            "wcwidth                                  0.2.14\n",
            "weasel                                   0.4.1\n",
            "webcolors                                24.11.1\n",
            "webencodings                             0.5.1\n",
            "websocket-client                         1.9.0\n",
            "websockets                               15.0.1\n",
            "Werkzeug                                 3.1.3\n",
            "wheel                                    0.45.1\n",
            "widgetsnbextension                       3.6.10\n",
            "wordcloud                                1.9.4\n",
            "wrapt                                    1.17.3\n",
            "wurlitzer                                3.1.1\n",
            "xarray                                   2025.10.1\n",
            "xarray-einstats                          0.9.1\n",
            "xgboost                                  3.0.5\n",
            "xlrd                                     2.0.2\n",
            "xxhash                                   3.6.0\n",
            "xyzservices                              2025.4.0\n",
            "yarl                                     1.22.0\n",
            "ydf                                      0.13.0\n",
            "yellowbrick                              1.5\n",
            "yfinance                                 0.2.66\n",
            "zict                                     3.0.0\n",
            "zipp                                     3.23.0\n",
            "zstandard                                0.25.0\n"
          ]
        }
      ]
    }
  ]
}